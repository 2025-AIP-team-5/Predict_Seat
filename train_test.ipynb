{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset upload"
      ],
      "metadata": {
        "id": "WYg6jXNcGDs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "-Ze2X1NSAD3b",
        "outputId": "33623d1a-f717-4fe3-82b0-cf451a5f92f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22d202b0-1ee9-4c8b-93f5-b7c4ca7d0733\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22d202b0-1ee9-4c8b-93f5-b7c4ca7d0733\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving B2_data.xlsx - w1.csv to B2_data.xlsx - w1.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1    2    3    4    5    6    7    8   11   12  ...   48   51   52  \\\n",
              "index                                                    ...                  \n",
              "1000   0.0  0.0  0.0  0.0  0.0  1.0  0.0  NaN  1.0  0.0  ...  0.0  NaN  0.0   \n",
              "1030   1.0  0.0  0.0  1.0  0.0  1.0  0.0  NaN  0.0  0.0  ...  0.0  NaN  0.0   \n",
              "1100   1.0  0.0  0.0  1.0  0.0  1.0  0.0  NaN  0.0  0.0  ...  0.0  NaN  0.0   \n",
              "1130   1.0  0.0  0.0  1.0  0.0  1.0  0.0  NaN  0.0  0.0  ...  0.0  NaN  0.0   \n",
              "1200   1.0  0.0  1.0  1.0  1.0  0.0  1.0  NaN  0.0  0.0  ...  0.0  NaN  1.0   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "1400   0.0  1.0  1.0  1.0  0.0  1.0  0.0  NaN  1.0  0.0  ...  0.0  NaN  0.0   \n",
              "1430   0.0  1.0  1.0  1.0  0.0  1.0  0.0  NaN  1.0  0.0  ...  0.0  NaN  0.0   \n",
              "1500   0.0  1.0  1.0  1.0  0.0  1.0  0.0  NaN  1.0  0.0  ...  0.0  NaN  0.0   \n",
              "1530   0.0  1.0  1.0  0.0  0.0  1.0  0.0  NaN  1.0  0.0  ...  0.0  NaN  1.0   \n",
              "1600   0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  NaN  1.0  ...  0.0  0.0  NaN   \n",
              "\n",
              "        53   54   55   56   57   58   59  \n",
              "index                                     \n",
              "1000   0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "1030   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1100   0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1130   0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
              "1200   0.0  1.0  0.0  0.0  0.0  1.0  1.0  \n",
              "...    ...  ...  ...  ...  ...  ...  ...  \n",
              "1400   1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "1430   1.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
              "1500   1.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
              "1530   1.0  0.0  1.0  1.0  0.0  1.0  0.0  \n",
              "1600   1.0  1.0  0.0  1.0  1.0  0.0  1.0  \n",
              "\n",
              "[61 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8d32563-7794-48de-8a1d-6272ef0b664c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>...</th>\n",
              "      <th>48</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1100</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1530</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1600</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8d32563-7794-48de-8a1d-6272ef0b664c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8d32563-7794-48de-8a1d-6272ef0b664c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8d32563-7794-48de-8a1d-6272ef0b664c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e03fc31c-8342-460e-8fc1-ddfa733530cc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e03fc31c-8342-460e-8fc1-ddfa733530cc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e03fc31c-8342-460e-8fc1-ddfa733530cc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4fae5324-f226-4ab6-8f8b-5b270400e689\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4fae5324-f226-4ab6-8f8b-5b270400e689 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# csv upload\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "df = df.dropna(how='all')\n",
        "\n",
        "if 'index' in df.columns:\n",
        "    df = df.set_index('index')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preprocessing"
      ],
      "metadata": {
        "id": "sJc9FAPlGK_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# column 'index' => 'time'\n",
        "df = df.rename(columns={\"index\": \"time\"})\n",
        "df = df.set_index(\"time\")\n",
        "\n",
        "# remove 'NaN'\n",
        "df = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "id": "1JNYeq5cDFQY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seat_matrix = df.T\n",
        "# columns_to_drop = [col for col in se at_matrix.columns if str(col).isdigit() and int(col) >= 1300]\n",
        "# seat_matrix = seat_matrix.drop(columns=columns_to_drop)\n",
        "\n",
        "seat_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "0RWIWfOfE3he",
        "outputId": "f974c993-920a-4da4-ff15-d46bb53e098c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time         1000  1030  1100  1130  1200  1230  1300  1330  1400  1430  ...  \\\n",
              "1               0     1     1     1     1     1     1     1     1     1  ...   \n",
              "2               0     0     0     0     0     0     0     0     0     0  ...   \n",
              "3               0     0     0     0     1     1     1     1     1     1  ...   \n",
              "4               0     1     1     1     1     1     1     1     1     0  ...   \n",
              "5               0     0     0     0     1     1     1     1     1     1  ...   \n",
              "6               1     1     1     1     0     0     1     1     1     1  ...   \n",
              "7               0     0     0     0     1     1     1     1     1     1  ...   \n",
              "8               0     0     0     0     0     0     0     0     0     0  ...   \n",
              "11              1     0     0     0     0     0     0     0     1     1  ...   \n",
              "12              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "13              0     0     0     0     0     0     0     1     1     1  ...   \n",
              "14              0     0     0     0     0     0     0     1     1     1  ...   \n",
              "15              0     1     1     0     1     1     1     1     1     1  ...   \n",
              "16              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "17              0     0     0     0     0     0     0     0     1     1  ...   \n",
              "18              1     1     1     1     1     1     1     1     1     1  ...   \n",
              "21              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "22              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "23              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "24              0     0     0     0     0     0     0     1     1     1  ...   \n",
              "25              0     1     1     1     1     1     1     1     1     0  ...   \n",
              "26              1     0     0     0     0     0     1     1     1     1  ...   \n",
              "27              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "28              1     1     0     0     1     1     1     1     1     1  ...   \n",
              "31              1     0     0     0     1     1     1     1     1     1  ...   \n",
              "32              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "33              0     1     1     1     1     1     1     1     1     1  ...   \n",
              "34              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "35              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "36              1     1     1     1     1     1     1     1     1     1  ...   \n",
              "37              0     0     0     0     0     0     0     1     0     0  ...   \n",
              "38              1     1     1     1     1     1     1     1     1     1  ...   \n",
              "41              1     1     1     1     1     1     1     1     1     1  ...   \n",
              "42              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "43              0     0     1     1     1     1     1     1     1     1  ...   \n",
              "44              0     1     1     1     0     0     0     0     0     0  ...   \n",
              "45              1     1     1     1     1     1     1     1     1     1  ...   \n",
              "46              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "47              1     0     0     0     0     1     1     1     1     1  ...   \n",
              "48              0     0     0     0     0     0     1     1     1     1  ...   \n",
              "51              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "52              0     0     0     0     1     1     1     1     1     1  ...   \n",
              "53              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "54              0     0     1     1     1     1     1     1     1     1  ...   \n",
              "55              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "56              1     0     0     0     0     1     1     1     1     1  ...   \n",
              "57              0     0     0     0     0     0     0     0     0     0  ...   \n",
              "58              0     0     0     1     1     1     1     1     1     1  ...   \n",
              "Unnamed: 49    58     0     0     0     1     1     1     1     1     1  ...   \n",
              "\n",
              "time         1130  1200  1230  1300  1330  1400  1430  1500  1530  1600  \n",
              "1               0     0     0     0     0     0     0     0     0     0  \n",
              "2               0     0     1     1     1     1     1     1     1     0  \n",
              "3               0     0     0     0     0     1     1     1     1     1  \n",
              "4               1     1     1     1     1     1     1     1     0     1  \n",
              "5               0     0     0     0     0     0     0     0     0     0  \n",
              "6               1     1     1     1     1     1     1     1     1     0  \n",
              "7               0     0     0     0     0     0     0     0     0     1  \n",
              "8               0     0     0     0     0     0     0     0     0     0  \n",
              "11              0     0     1     1     1     1     1     1     1     0  \n",
              "12              0     0     0     0     0     0     0     0     0     1  \n",
              "13              0     0     0     0     0     0     0     0     0     0  \n",
              "14              0     0     0     0     0     0     0     0     0     0  \n",
              "15              0     0     0     0     0     0     0     0     0     0  \n",
              "16              0     0     0     0     0     0     0     0     0     0  \n",
              "17              1     1     1     1     1     1     1     1     1     0  \n",
              "18              0     0     0     0     0     0     0     0     0     1  \n",
              "21              1     1     1     1     1     1     1     1     1     0  \n",
              "22              0     0     0     0     0     0     0     0     0     1  \n",
              "23              0     0     0     0     0     0     0     1     1     0  \n",
              "24              0     1     1     1     1     1     1     1     0     1  \n",
              "25              0     0     0     0     0     0     0     0     0     0  \n",
              "26              0     0     0     0     0     0     0     0     0     0  \n",
              "27              1     1     1     1     1     1     1     1     1     0  \n",
              "28              0     0     0     0     0     0     0     0     0     1  \n",
              "31              0     0     0     0     0     0     0     0     0     0  \n",
              "32              1     1     1     1     1     1     1     1     1     0  \n",
              "33              0     0     0     0     0     0     0     0     0     1  \n",
              "34              0     0     0     0     0     0     0     1     1     0  \n",
              "35              0     0     0     0     0     0     0     0     0     1  \n",
              "36              0     0     0     1     1     1     1     1     1     0  \n",
              "37              0     0     0     0     0     0     0     0     0     1  \n",
              "38              0     0     1     1     1     1     1     0     0     0  \n",
              "41              0     1     1     1     1     1     1     1     1     0  \n",
              "42              0     0     0     0     0     0     0     0     0     1  \n",
              "43              0     0     0     0     0     0     0     0     0     0  \n",
              "44              0     0     0     0     1     1     1     1     1     0  \n",
              "45              0     0     0     0     0     0     0     0     0     1  \n",
              "46              1     1     1     1     1     1     1     1     1     0  \n",
              "47              0     0     0     0     0     0     0     0     0     1  \n",
              "48              1     1     1     1     0     0     0     0     0     0  \n",
              "51              0     0     0     0     0     0     0     0     0     0  \n",
              "52              0     0     0     0     0     0     0     0     1     0  \n",
              "53              1     1     1     1     1     1     1     1     1     1  \n",
              "54              0     0     0     0     0     0     0     0     0     1  \n",
              "55              0     0     0     0     0     0     1     1     1     0  \n",
              "56              1     1     1     1     1     1     1     1     1     1  \n",
              "57              0     0     0     0     0     0     0     0     0     1  \n",
              "58              0     0     0     0     0     0     0     0     1     0  \n",
              "Unnamed: 49     0     0     0     0     0     0     0     0     0     1  \n",
              "\n",
              "[49 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5eaa8f5f-88a3-463a-aae3-8d30c204bcce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>time</th>\n",
              "      <th>1000</th>\n",
              "      <th>1030</th>\n",
              "      <th>1100</th>\n",
              "      <th>1130</th>\n",
              "      <th>1200</th>\n",
              "      <th>1230</th>\n",
              "      <th>1300</th>\n",
              "      <th>1330</th>\n",
              "      <th>1400</th>\n",
              "      <th>1430</th>\n",
              "      <th>...</th>\n",
              "      <th>1130</th>\n",
              "      <th>1200</th>\n",
              "      <th>1230</th>\n",
              "      <th>1300</th>\n",
              "      <th>1330</th>\n",
              "      <th>1400</th>\n",
              "      <th>1430</th>\n",
              "      <th>1500</th>\n",
              "      <th>1530</th>\n",
              "      <th>1600</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 49</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5eaa8f5f-88a3-463a-aae3-8d30c204bcce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5eaa8f5f-88a3-463a-aae3-8d30c204bcce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5eaa8f5f-88a3-463a-aae3-8d30c204bcce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e85eaf55-4163-4e07-9205-7309b2f1da7c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e85eaf55-4163-4e07-9205-7309b2f1da7c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e85eaf55-4163-4e07-9205-7309b2f1da7c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0db55521-5f7f-4be5-95e2-ea4618f11517\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('seat_matrix')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0db55521-5f7f-4be5-95e2-ea4618f11517 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('seat_matrix');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "seat_matrix"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "stXLPkn1Gn5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate similarity betweens seats"
      ],
      "metadata": {
        "id": "ynGq34J7GPgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "Haw9CkZTR6G7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### type1. Jaccard Similarity"
      ],
      "metadata": {
        "id": "DVHLLE9dHo-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def jaccard_similarity(a, b):\n",
        "    \"\"\"0/1 벡터 두 개 사이의 Jaccard similarity 계산\"\"\"\n",
        "    intersection = np.logical_and(a, b).sum()\n",
        "    union = np.logical_or(a, b).sum()\n",
        "    if union == 0:\n",
        "        return 0.0  # 둘 다 0이면 유사도 0으로 간주\n",
        "    return intersection / union\n",
        "\n",
        "def generate_edge_index_jaccard(df, threshold=0):\n",
        "    df = df.fillna(0)\n",
        "    seat_data = (df.T.values > 0.5).astype(int)  # 공석/착석 0/1 정규화\n",
        "    num_nodes = seat_data.shape[0]\n",
        "\n",
        "    edge_index = []\n",
        "    edge_weight = []\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if i == j:\n",
        "                edge_index.append([i, j])\n",
        "                edge_weight.append(1.0)\n",
        "            else:\n",
        "                sim = jaccard_similarity(seat_data[i], seat_data[j])\n",
        "                if sim >= threshold:\n",
        "                    edge_index.append([i, j])\n",
        "                    edge_weight.append(sim)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).T\n",
        "    edge_weight = torch.tensor(edge_weight, dtype=torch.float32)\n",
        "\n",
        "    return edge_index, edge_weight\n"
      ],
      "metadata": {
        "id": "wBC5Mu4-Huph"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### type2. correlated score"
      ],
      "metadata": {
        "id": "XUfx5SazHi-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_edge_index_coreelated(df, threshold=0, inv_threshold=0):\n",
        "    df = df.fillna(0)\n",
        "    seat_data = df.T.values\n",
        "    corr_matrix = np.corrcoef(seat_data)\n",
        "\n",
        "    edge_index = []\n",
        "    edge_weight = []\n",
        "\n",
        "    num_nodes = corr_matrix.shape[0]\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            value = corr_matrix[i, j]\n",
        "            if i != j and not np.isnan(value) and (value >= threshold or value <= inv_threshold):\n",
        "                edge_index.append([i, j])\n",
        "                edge_weight.append(value)\n",
        "            elif i == j:\n",
        "                edge_index.append([i, j])\n",
        "                edge_weight.append(1.0)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).T\n",
        "    edge_weight = torch.tensor(edge_weight, dtype=torch.float32)\n",
        "\n",
        "    return edge_index, edge_weight"
      ],
      "metadata": {
        "id": "UMFU1BIHRfOO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## type3: DTW"
      ],
      "metadata": {
        "id": "XdAax73_tTA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dtaidistance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaRtzasQteSr",
        "outputId": "64ad840c-8278-42f3-a9b8-482477db2092"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dtaidistance\n",
            "  Downloading dtaidistance-2.3.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from dtaidistance) (2.0.2)\n",
            "Downloading dtaidistance-2.3.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/3.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dtaidistance\n",
            "Successfully installed dtaidistance-2.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dtaidistance import dtw\n",
        "\n",
        "def generate_dtw_edges(df, threshold=0.5, max_distance=None, self_loop=True):\n",
        "    \"\"\"\n",
        "    df: pandas DataFrame, shape = (시간, 좌석수)\n",
        "    threshold: DTW 유사도 기준 거리 값 (낮을수록 유사)\n",
        "    max_distance: DTW 거리를 정규화할 최대 값 (없으면 자동)\n",
        "    self_loop: 자기 자신 엣지 포함 여부\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.fillna(0)\n",
        "    seat_data = df.T.values  # 좌석별 시계열 (좌석 x 시간)\n",
        "\n",
        "    num_nodes = seat_data.shape[0]\n",
        "    edge_index = []\n",
        "    edge_weight = []\n",
        "\n",
        "    # DTW 거리 계산\n",
        "    distances = np.zeros((num_nodes, num_nodes))\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if i == j and not self_loop:\n",
        "                continue\n",
        "            dist = dtw.distance(seat_data[i], seat_data[j])\n",
        "            distances[i, j] = dist\n",
        "\n",
        "    # 정규화\n",
        "    if max_distance is None:\n",
        "        max_distance = np.max(distances)\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if i == j and not self_loop:\n",
        "                continue\n",
        "            norm_dist = distances[i, j] / max_distance\n",
        "            sim = 1.0 - norm_dist  # 유사도 = 1 - 거리\n",
        "            if sim >= threshold:\n",
        "                edge_index.append([i, j])\n",
        "                edge_weight.append(sim)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).T  # shape [2, num_edges]\n",
        "    edge_weight = torch.tensor(edge_weight, dtype=torch.float32)\n",
        "\n",
        "    return edge_index, edge_weight"
      ],
      "metadata": {
        "id": "_QMg94dptVac"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index, edge_weight = generate_edge_index_jaccard(df)\n",
        "print(edge_index.shape)  # [2, num_edges]\n",
        "print(edge_weight.shape)  # [2, num_edges]\n",
        "edge_index, edge_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rILf11akRuBs",
        "outputId": "15eca190-ab9b-4d62-b921-bc0c4a69c4f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2401])\n",
            "torch.Size([2401])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  0,  0,  ..., 48, 48, 48],\n",
              "         [ 0,  1,  2,  ..., 46, 47, 48]]),\n",
              " tensor([1.0000, 0.0244, 0.7059,  ..., 0.0357, 0.6970, 1.0000]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYTD-DIItUL",
        "outputId": "ba6664b8-744a-42e3-a4c8-76ee3613cfd0",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cpu\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation"
      ],
      "metadata": {
        "id": "dh39DOmfITFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(1, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        return x  # [num_nodes, hidden_dim]\n",
        "\n",
        "class GNNRNNPredictor(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim=32, rnn_type='LSTM'):\n",
        "        super().__init__()\n",
        "        self.gnn = GNNEncoder(hidden_dim)\n",
        "        if rnn_type == 'GRU':\n",
        "            self.rnn = torch.nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = torch.nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        self.output_layer = torch.nn.Linear(hidden_dim, 1)  # 예측값: 공석 확률\n",
        "\n",
        "    def forward(self, x_seq, edge_index, edge_weight=None):\n",
        "        # x_seq: [seq_len, num_nodes, 1]\n",
        "        h_list = []\n",
        "        for x in x_seq:\n",
        "            h = self.gnn(x, edge_index, edge_weight=edge_weight)  # [num_nodes, hidden_dim]\n",
        "            h_list.append(h.unsqueeze(0))  # [1, num_nodes, hidden_dim]\n",
        "\n",
        "        h_seq = torch.cat(h_list, dim=0)  # [seq_len, num_nodes, hidden_dim]\n",
        "        h_seq = h_seq.permute(1, 0, 2)    # → [batch=num_nodes, seq_len, hidden_dim]\n",
        "\n",
        "        output, _ = self.rnn(h_seq)       # [num_nodes, seq_len, hidden_dim]\n",
        "        last_h = output[:, -1, :]         # 마지막 시점 hidden 상태\n",
        "\n",
        "        y_pred = self.output_layer(last_h)  # [num_nodes, 1]\n",
        "        return torch.sigmoid(y_pred)        # 예측된 공석 확률"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tkNGBLxVHQb",
        "outputId": "88ccb931-31b4-422f-b127-7adbd030ae9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SignedConv\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class SignedGNNEncoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        # 양 엣지 (positive edge) 처리용 GCN\n",
        "        self.gcn_pos1 = GCNConv(1, hidden_dim)\n",
        "        self.gcn_pos2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "        # 음 엣지 (negative edge) 처리용 GCN\n",
        "        self.gcn_neg1 = GCNConv(1, hidden_dim)\n",
        "        self.gcn_neg2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight):\n",
        "        # 양 엣지 처리\n",
        "        x_pos = F.relu(self.gcn_pos1(x, pos_edge_index, pos_edge_weight))\n",
        "        x_pos = self.gcn_pos2(x_pos, pos_edge_index, pos_edge_weight)\n",
        "\n",
        "        # 음 엣지 처리\n",
        "        x_neg = F.relu(self.gcn_neg1(x, neg_edge_index, neg_edge_weight))\n",
        "        x_neg = self.gcn_neg2(x_neg, neg_edge_index, neg_edge_weight)\n",
        "\n",
        "        # 결합 (평균 또는 concat)\n",
        "        x_combined = (x_pos + x_neg) / 2\n",
        "        return x_combined  # [num_nodes, hidden_dim]\n",
        "\n",
        "\n",
        "class SignedGNNRNNPredictor(nn.Module):\n",
        "    def __init__(self, hidden_dim=32, rnn_type='LSTM'):\n",
        "        super().__init__()\n",
        "        self.gnn = SignedGNNEncoder(hidden_dim)\n",
        "        if rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x_seq, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight):\n",
        "        h_list = []\n",
        "        for x in x_seq:\n",
        "            h = self.gnn(x, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight)\n",
        "            h_list.append(h.unsqueeze(0))\n",
        "\n",
        "        h_seq = torch.cat(h_list, dim=0)  # [seq_len, num_nodes, hidden_dim]\n",
        "        h_seq = h_seq.permute(1, 0, 2)    # [num_nodes, seq_len, hidden_dim]\n",
        "        output, _ = self.rnn(h_seq)\n",
        "        last_h = output[:, -1, :]\n",
        "        y_pred = self.output_layer(last_h)\n",
        "        return torch.sigmoid(y_pred)"
      ],
      "metadata": {
        "id": "HGkus8g8Vwoi"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "wCZISsxxNND5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence_dataset(df, sequence_length=4):\n",
        "    df = df.fillna(0)\n",
        "    seat_vectors = df.values  # shape: [time_steps, num_seats]\n",
        "\n",
        "    X_seq_list = []\n",
        "    Y_target_list = []\n",
        "\n",
        "    for i in range(len(seat_vectors) - sequence_length):\n",
        "        x_seq = seat_vectors[i:i+sequence_length]         # [sequence_length, num_seats]\n",
        "        y_target = seat_vectors[i+sequence_length]        # [num_seats]\n",
        "\n",
        "        x_seq_tensor = torch.tensor(x_seq, dtype=torch.float32).unsqueeze(-1)  # [seq_len, num_seats, 1]\n",
        "        y_target_tensor = torch.tensor(y_target, dtype=torch.float32).unsqueeze(-1)  # [num_seats, 1]\n",
        "\n",
        "        X_seq_list.append(x_seq_tensor)\n",
        "        Y_target_list.append(y_target_tensor)\n",
        "\n",
        "    return X_seq_list, Y_target_list"
      ],
      "metadata": {
        "id": "e1Z15WZGWE4S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X, Y, edge_index, edge_weight=None, strict_mode=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_elements = 0\n",
        "    change_correct = 0\n",
        "    change_elements = 0\n",
        "\n",
        "    loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_seq, y_target in zip(X, Y):\n",
        "            y_target = y_target.clamp(0, 1)\n",
        "            y_pred = model(x_seq, edge_index, edge_weight)\n",
        "\n",
        "            loss = loss_fn(y_pred, y_target)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred_binary = (y_pred > 0.5).float()\n",
        "\n",
        "            if strict_mode:\n",
        "              for i in range(len(y_pred)):\n",
        "                if y_pred[i] != x_seq[-1][i]:\n",
        "                  if pred_binary[i] == 1 and y_pred[i] < 0.7:\n",
        "                    pred_binary[i] = 0\n",
        "                  elif pred_binary[i] == 0 and y_pred[i] > 0.3:\n",
        "                    pred_binary[i] = 1\n",
        "\n",
        "            correct = (pred_binary == y_target).sum().item()\n",
        "            total_correct += correct\n",
        "            total_elements += y_target.numel()\n",
        "\n",
        "            # measure change detection accuracy\n",
        "            change_mask = (x_seq[-1] != y_target)\n",
        "            change_correct += ((pred_binary == y_target) * change_mask).sum().item()\n",
        "            change_elements += change_mask.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(X)\n",
        "    accuracy = total_correct / total_elements\n",
        "    change_accuracy = change_correct / change_elements if change_elements > 0 else 0.0\n",
        "    return avg_loss, accuracy, change_accuracy\n"
      ],
      "metadata": {
        "id": "8DRWyZlIIjO8"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_signedGNN(model, X, Y, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight, strict_mode=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_elements = 0\n",
        "    change_correct = 0\n",
        "    change_elements = 0\n",
        "\n",
        "    loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_seq, y_target in zip(X, Y):\n",
        "            y_target = y_target.clamp(0, 1)\n",
        "            y_pred = model(x_seq, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight)\n",
        "\n",
        "            loss = loss_fn(y_pred, y_target)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred_binary = (y_pred > 0.5).float()\n",
        "\n",
        "            if strict_mode:\n",
        "              for i in range(len(y_pred)):\n",
        "                if y_pred[i] != x_seq[-1][i]:\n",
        "                  if pred_binary[i] == 1 and y_pred[i] < 0.7:\n",
        "                    pred_binary[i] = 0\n",
        "                  elif pred_binary[i] == 0 and y_pred[i] > 0.3:\n",
        "                    pred_binary[i] = 1\n",
        "\n",
        "            correct = (pred_binary == y_target).sum().item()\n",
        "            total_correct += correct\n",
        "            total_elements += y_target.numel()\n",
        "\n",
        "            # measure change detection accuracy\n",
        "            change_mask = (x_seq[-1] != y_target)\n",
        "            change_correct += ((pred_binary == y_target) * change_mask).sum().item()\n",
        "            change_elements += change_mask.sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(X)\n",
        "    accuracy = total_correct / total_elements\n",
        "    change_accuracy = change_correct / change_elements if change_elements > 0 else 0.0\n",
        "    return avg_loss, accuracy, change_accuracy"
      ],
      "metadata": {
        "id": "4fi8XuEsY-mD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_seq_list, Y_target_list, X_val, Y_val, edge_index, edge_weight=None, epochs=200, lr=0.001, patience=10, strict_mode=False):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = torch.nn.BCELoss()  # Binary classification: 공석/착석\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for x_seq, y_target in zip(X_seq_list, Y_target_list):\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_seq, edge_index, edge_weight)  # [num_nodes, 1]\n",
        "            loss = loss_fn(y_pred, y_target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(X_seq_list)\n",
        "        val_loss, val_acc, val_change_acc = evaluate(model, X_val, Y_val, edge_index, edge_weight, strict_mode=strict_mode)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            patience_count = 0\n",
        "        else:\n",
        "          patience_count += 1\n",
        "\n",
        "        # ealry stopping\n",
        "        if patience_count >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        print(f\"[{epoch+1}/{epochs}] Train Loss: {avg_train_loss:.4f} / Val Loss: {val_loss:.4f} / Val Acc: {val_acc:.4f} / Change Acc: {val_change_acc:.4f}\")\n",
        "\n",
        "    if best_model_state:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model\n",
        "\n",
        "def split_sequence_dataset(X_seq_list, Y_target_list, train_ratio=0.8):\n",
        "    N = len(X_seq_list)\n",
        "    split = int(N * train_ratio)\n",
        "    X_train, Y_train = X_seq_list[:split], Y_target_list[:split]\n",
        "    X_test, Y_test = X_seq_list[split:], Y_target_list[split:]\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "metadata": {
        "id": "wmsJE1XQWHZG"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_signedGNN(model, X_seq_list, Y_target_list, X_val, Y_val, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight,\n",
        "          epochs=200, lr=0.001, patience=10, strict_mode=False):\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    patience_count = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for x_seq, y_target in zip(X_seq_list, Y_target_list):\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_seq, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight)  # 🔹 수정됨\n",
        "            loss = loss_fn(y_pred, y_target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(X_seq_list)\n",
        "        val_loss, val_acc, val_change_acc = evaluate_signedGNN(\n",
        "            model, X_val, Y_val, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight, strict_mode=strict_mode\n",
        "        )\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            patience_count = 0\n",
        "        else:\n",
        "            patience_count += 1\n",
        "\n",
        "        if patience_count >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        print(f\"[{epoch+1}/{epochs}] Train Loss: {avg_train_loss:.4f} / \"\n",
        "              f\"Val Loss: {val_loss:.4f} / Val Acc: {val_acc:.4f} / Change Acc: {val_change_acc:.4f}\")\n",
        "\n",
        "    if best_model_state:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "WEriLph1Zq5y"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Example"
      ],
      "metadata": {
        "id": "7rdXbLLoRi7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: edge_index 생성\n",
        "# edge_index, edge_weight = generate_edge_index_with_weights(df, threshold=0.7, inv_threshold=-1.1)\n",
        "# print(edge_weight.shape)\n",
        "\n",
        "def identity_edge_index(num_nodes):\n",
        "    return torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)])\n",
        "edge_weight = None\n",
        "edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "\n",
        "\n",
        "# Step 3: 시퀀스 학습 데이터 준비\n",
        "X_seq_list, Y_target_list = create_sequence_dataset(df, sequence_length=4)\n",
        "X_train, Y_train, X_val, Y_val = split_sequence_dataset(X_seq_list, Y_target_list)\n",
        "\n",
        "# Step 4: 모델 정의 및 훈련\n",
        "model = GNNRNNPredictor(hidden_dim=32)\n",
        "train(model, X_train, Y_train, X_val, Y_val, edge_index, edge_weight)"
      ],
      "metadata": {
        "id": "dJ3pDyTbWM56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "Fl9hoh9GIkJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    df_test = pd.read_csv(filename)\n",
        "\n",
        "df_test = df_test.dropna(how='all')\n",
        "\n",
        "if 'index' in df_test.columns:\n",
        "    df_test = df_test.set_index('index')\n",
        "\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "EhTP8xUqgDIS",
        "outputId": "c5a304c9-0900-41da-a5b4-3e04e6cf9146"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a5fd725-ce5f-48a4-befe-aa4e8f6fde26\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a5fd725-ce5f-48a4-befe-aa4e8f6fde26\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving B2_data.xlsx - w2 (1).csv to B2_data.xlsx - w2 (1) (2).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       1  2  3  4  5  6  7   8  11  12  ...  48  51  52  53  54  55  56  57  \\\n",
              "index                                   ...                                   \n",
              "1000   0  1  0  1  0  1  0 NaN   0   0  ...   1 NaN   0   0   0   0   1   0   \n",
              "1030   0  1  1  1  0  1  0 NaN   0   0  ...   1 NaN   0   0   0   1   1   0   \n",
              "1100   0  0  1  0  1  1  1 NaN   1   0  ...   1 NaN   0   1   0   0   0   0   \n",
              "1130   0  0  1  0  1  1  1 NaN   1   0  ...   1 NaN   0   1   0   0   0   0   \n",
              "1200   0  0  1  1  1  1  1 NaN   1   0  ...   1 NaN   0   1   0   0   1   0   \n",
              "1230   0  1  1  1  1  1  1 NaN   1   0  ...   1 NaN   0   1   0   1   1   0   \n",
              "1300   0  1  1  1  1  1  1 NaN   1   0  ...   1 NaN   1   1   0   1   1   0   \n",
              "1330   1  1  1  1  1  1  1 NaN   1   0  ...   1 NaN   1   1   0   1   1   0   \n",
              "1400   1  1  1  1  1  1  1 NaN   1   0  ...   1 NaN   1   1   0   1   1   0   \n",
              "1430   1  1  1  1  1  1  1 NaN   1   0  ...   1 NaN   1   1   0   1   1   0   \n",
              "1500   1  0  1  1  1  1  1 NaN   1   0  ...   1 NaN   1   0   1   0   1   0   \n",
              "1530   1  0  1  1  1  1  1 NaN   1   0  ...   1 NaN   1   0   1   0   1   0   \n",
              "\n",
              "       58  59  \n",
              "index          \n",
              "1000    0 NaN  \n",
              "1030    0 NaN  \n",
              "1100    1 NaN  \n",
              "1130    1 NaN  \n",
              "1200    1 NaN  \n",
              "1230    1 NaN  \n",
              "1300    1 NaN  \n",
              "1330    1 NaN  \n",
              "1400    1 NaN  \n",
              "1430    1 NaN  \n",
              "1500    1 NaN  \n",
              "1530    1 NaN  \n",
              "\n",
              "[12 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acc8c39e-a22f-42f3-b995-227abe755a50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>...</th>\n",
              "      <th>48</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1100</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1300</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1330</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1530</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acc8c39e-a22f-42f3-b995-227abe755a50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acc8c39e-a22f-42f3-b995-227abe755a50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acc8c39e-a22f-42f3-b995-227abe755a50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8472ebd9-da5b-4e34-a5f8-04fffaed6499\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8472ebd9-da5b-4e34-a5f8-04fffaed6499')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8472ebd9-da5b-4e34-a5f8-04fffaed6499 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4aa3063b-44df-407f-85a4-47e7d42fad34\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4aa3063b-44df-407f-85a4-47e7d42fad34 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, Y_test = create_sequence_dataset(df_test, sequence_length=4)\n",
        "test_loss, test_accuracy, test_tot_acc =  evaluate(model, X_test, Y_test, edge_index, edge_weight)\n",
        "print(f\"Test Loss: {test_loss:.4f} / Test Accuracy: {test_tot_acc:.4f} / Test Change Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jSULJ2Dg7_t",
        "outputId": "0560aea6-673a-4c55-b015-8b25ca81815f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5341 / Test Accuracy: 0.6562 / Test Change Accuracy: 0.7551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridCV"
      ],
      "metadata": {
        "id": "V7anf5LCIt65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph Implementation\n",
        "\n",
        "def generate_graph(df, criteria, threshold=0, inv_threshold=0):\n",
        "  if criteria == \"jaccard\":\n",
        "    edge_index, edge_weight = generate_edge_index_jaccard(df, threshold=threshold)\n",
        "  elif criteria == \"correlated\":\n",
        "    edge_index, edge_weight = generate_edge_index_coreelated(df, threshold=threshold, inv_threshold=inv_threshold)\n",
        "  elif criteria == \"dtw\":\n",
        "    edge_index, edge_weight = generate_dtw_edges(df, threshold=threshold)\n",
        "  elif criteria == \"baseline\":\n",
        "    edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "    edge_weight = None\n",
        "\n",
        "\n",
        "  return edge_index, edge_weight\n",
        "\n",
        "edge_index, edge_weight = generate_graph(df, 'jaccard')"
      ],
      "metadata": {
        "id": "eib9bswWQCSY"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def grid_search(graph_criteria, X_train, Y_train, X_val, Y_val, edge_index, edge_weight, threshold=0, inv_threshold=0):\n",
        "    edge_index, edge_weight = generate_graph(df, graph_criteria, threshold=threshold, inv_threshold=inv_threshold)\n",
        "    threshold_type = f\"{inv_threshold}+{threshold}\"\n",
        "    if threshold == 0 and inv_threshold == 0:\n",
        "      threshold_type = \"fc\"\n",
        "    elif graph_criteria == \"jaccard\" and threshold != 0:\n",
        "      threshold_type = f\"threshold_{threshold}\"\n",
        "    elif graph_criteria == \"correlated\" and inv_threshold == -1:\n",
        "      threshold_type = f\"only_plus_{threshold}\"\n",
        "    elif graph_criteria == \"correlated\" and threshold != 0 and inv_threshold == 0:\n",
        "      threshold_type = f\"with_inv_{threshold}\"\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_config = None\n",
        "    best_model = None\n",
        "    result = []\n",
        "\n",
        "\n",
        "    # Hyperparameter grid\n",
        "    lrs = [0.01, 0.001, 0.0001]\n",
        "    hidden_dims = [32, 64, 128]\n",
        "    strict_modes = [False, True]\n",
        "\n",
        "    for lr, hidden_dim, strict_mode in product(lrs, hidden_dims, strict_modes):\n",
        "      print(f\"Training with lr={lr}, hidden_dim={hidden_dim}, strict_mode={strict_mode}\")\n",
        "\n",
        "      model = GNNRNNPredictor(hidden_dim=hidden_dim)\n",
        "      model = train(model, X_train, Y_train, X_val, Y_val, edge_index, edge_weight, lr=lr, strict_mode=strict_mode)\n",
        "\n",
        "      test_loss, test_tot_acc, test_change_acc =  evaluate(model, X_test, Y_test, edge_index, edge_weight, strict_mode=strict_mode)\n",
        "      print(f'Test Result: test_loss={test_loss:.4f} / test_acc={test_tot_acc:.4f} / test_change_acc={test_change_acc:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U8iZ8N2BPDPq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_signed_edges_with_weights(edge_index, edge_weight):\n",
        "    \"\"\"\n",
        "    edge_index: Tensor [2, num_edges]\n",
        "    edge_weight: Tensor [num_edges]\n",
        "\n",
        "    Returns:\n",
        "    pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight\n",
        "    \"\"\"\n",
        "    # 양수, 음수 weight 마스크 생성\n",
        "    pos_mask = edge_weight > 0\n",
        "    neg_mask = edge_weight < 0\n",
        "\n",
        "    # 양의 엣지\n",
        "    pos_edge_index = edge_index[:, pos_mask]\n",
        "    pos_edge_weight = edge_weight[pos_mask]\n",
        "\n",
        "    # 음의 엣지\n",
        "    neg_edge_index = edge_index[:, neg_mask]\n",
        "    neg_edge_weight = edge_weight[neg_mask] * (-1)\n",
        "\n",
        "    return pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight\n",
        "\n",
        "def grid_search_signedGNN(graph_criteria, X_train, Y_train, X_val, Y_val, edge_index, edge_weight, threshold=0, inv_threshold=0):\n",
        "    edge_index, edge_weight = generate_graph(df, graph_criteria, threshold=threshold, inv_threshold=inv_threshold)\n",
        "    pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight = split_signed_edges_with_weights(edge_index, edge_weight)\n",
        "\n",
        "    threshold_type = f\"{inv_threshold}+{threshold}\"\n",
        "    if threshold == 0 and inv_threshold == 0:\n",
        "      threshold_type = \"fc\"\n",
        "    elif graph_criteria == \"jaccard\" and threshold != 0:\n",
        "      threshold_type = f\"threshold_{threshold}\"\n",
        "    elif graph_criteria == \"correlated\" and inv_threshold == -1:\n",
        "      threshold_type = f\"only_plus_{threshold}\"\n",
        "    elif graph_criteria == \"correlated\" and threshold != 0 and inv_threshold == 0:\n",
        "      threshold_type = f\"with_inv_{threshold}\"\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_config = None\n",
        "    best_model = None\n",
        "    result = []\n",
        "\n",
        "\n",
        "    # Hyperparameter grid\n",
        "    lrs = [0.01, 0.001, 0.0001]\n",
        "    hidden_dims = [32, 64, 128]\n",
        "    strict_modes = [False, True]\n",
        "\n",
        "    for lr, hidden_dim, strict_mode in product(lrs, hidden_dims, strict_modes):\n",
        "      print(f\"Training with lr={lr}, hidden_dim={hidden_dim}, strict_mode={strict_mode}\")\n",
        "\n",
        "      model = SignedGNNRNNPredictor(hidden_dim=hidden_dim)\n",
        "      model = train_signedGNN(model, X_train, Y_train, X_val, Y_val, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight, lr=lr, strict_mode=strict_mode)\n",
        "\n",
        "      test_loss, test_tot_acc, test_change_acc =  evaluate_signedGNN(model, X_test, Y_test, pos_edge_index, pos_edge_weight, neg_edge_index, neg_edge_weight, strict_mode=strict_mode)\n",
        "      print(f'Test Result: test_loss={test_loss:.4f} / test_acc={test_tot_acc:.4f} / test_change_acc={test_change_acc:.4f}')\n",
        "\n",
        "\n",
        "      result.append({\n",
        "          \"lr\": lr,\n",
        "          \"hidden_dim\": hidden_dim,\n",
        "          \"strict_mode\": strict_mode,\n",
        "          \"test_loss\": test_loss,\n",
        "          \"test_tot_acc\": test_tot_acc,\n",
        "          \"test_change_acc\": test_change_acc\n",
        "      })\n",
        "\n",
        "    result_df = pd.DataFrame(result)\n",
        "    result_df.to_csv(f\"result_signed_{graph_criteria}_{threshold_type}.csv\", index=False)\n",
        "\n",
        "\n",
        "    # print(f\"\\n Best Config: lr={best_config[0]}, hidden_dim={best_config[1]} (val_loss={best_val_loss:.4f})\")\n",
        "    # return best_model, best_config"
      ],
      "metadata": {
        "id": "MFEry5tnYG1Q"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_search(graph_criteria=\"jaccard\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.5, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"jaccard\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.7, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"jaccard\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.9, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"jaccard\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight)\n",
        "# grid_search(graph_criteria=\"correlated\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.5, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"correlated\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.7, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"correlated\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.9, inv_threshold=-1)\n",
        "grid_search_signedGNN(graph_criteria=\"correlated\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight)\n",
        "\n",
        "# grid_search(graph_criteria=\"dtw\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.5, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"dtw\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.7, inv_threshold=-1)\n",
        "# grid_search(graph_criteria=\"dtw\", X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, edge_index=edge_index, edge_weight=edge_weight, threshold=0.9, inv_threshold=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vDk8Bpk5UUIR",
        "outputId": "6154266d-fa60-4fd5-f2ac-0d507333d4c8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with lr=0.01, hidden_dim=32, strict_mode=False\n",
            "[1/200] Train Loss: 0.6859 / Val Loss: 0.6124 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.5985 / Val Loss: 0.8154 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.6268 / Val Loss: 0.5543 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[4/200] Train Loss: 0.5004 / Val Loss: 0.4891 / Val Acc: 0.7109 / Change Acc: 0.3091\n",
            "[5/200] Train Loss: 0.4644 / Val Loss: 0.5146 / Val Acc: 0.7075 / Change Acc: 0.3636\n",
            "[6/200] Train Loss: 0.4738 / Val Loss: 0.5202 / Val Acc: 0.7109 / Change Acc: 0.3636\n",
            "[7/200] Train Loss: 0.4553 / Val Loss: 0.4727 / Val Acc: 0.7330 / Change Acc: 0.2364\n",
            "[8/200] Train Loss: 0.4419 / Val Loss: 0.5208 / Val Acc: 0.7160 / Change Acc: 0.3091\n",
            "[9/200] Train Loss: 0.4401 / Val Loss: 0.4771 / Val Acc: 0.7177 / Change Acc: 0.2727\n",
            "[10/200] Train Loss: 0.4467 / Val Loss: 0.4751 / Val Acc: 0.7296 / Change Acc: 0.3091\n",
            "[11/200] Train Loss: 0.4404 / Val Loss: 0.4220 / Val Acc: 0.8112 / Change Acc: 0.0909\n",
            "[12/200] Train Loss: 0.4636 / Val Loss: 0.4805 / Val Acc: 0.7126 / Change Acc: 0.3273\n",
            "[13/200] Train Loss: 0.4379 / Val Loss: 0.4840 / Val Acc: 0.7160 / Change Acc: 0.3273\n",
            "[14/200] Train Loss: 0.4525 / Val Loss: 0.5062 / Val Acc: 0.7262 / Change Acc: 0.3636\n",
            "[15/200] Train Loss: 0.4580 / Val Loss: 0.5009 / Val Acc: 0.7177 / Change Acc: 0.3636\n",
            "[16/200] Train Loss: 0.4688 / Val Loss: 0.4648 / Val Acc: 0.7330 / Change Acc: 0.3273\n",
            "[17/200] Train Loss: 0.4288 / Val Loss: 0.4692 / Val Acc: 0.7364 / Change Acc: 0.2909\n",
            "[18/200] Train Loss: 0.4090 / Val Loss: 0.4945 / Val Acc: 0.7330 / Change Acc: 0.3091\n",
            "[19/200] Train Loss: 0.4077 / Val Loss: 0.5414 / Val Acc: 0.7109 / Change Acc: 0.3636\n",
            "[20/200] Train Loss: 0.4162 / Val Loss: 0.4315 / Val Acc: 0.7466 / Change Acc: 0.3091\n",
            "Early stopping at epoch 21\n",
            "Test Result: test_loss=0.5650 / test_acc=0.7577 / test_change_acc=0.3750\n",
            "Training with lr=0.01, hidden_dim=32, strict_mode=True\n",
            "[1/200] Train Loss: 0.7054 / Val Loss: 0.6554 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6450 / Val Loss: 0.5810 / Val Acc: 0.3350 / Change Acc: 0.6364\n",
            "[3/200] Train Loss: 0.5305 / Val Loss: 0.4744 / Val Acc: 0.7483 / Change Acc: 0.2727\n",
            "[4/200] Train Loss: 0.4891 / Val Loss: 0.4493 / Val Acc: 0.7517 / Change Acc: 0.4727\n",
            "[5/200] Train Loss: 0.4686 / Val Loss: 0.4649 / Val Acc: 0.7942 / Change Acc: 0.1455\n",
            "[6/200] Train Loss: 0.4505 / Val Loss: 0.5226 / Val Acc: 0.7857 / Change Acc: 0.1091\n",
            "[7/200] Train Loss: 0.4436 / Val Loss: 0.5471 / Val Acc: 0.7704 / Change Acc: 0.1455\n",
            "[8/200] Train Loss: 0.4360 / Val Loss: 0.5495 / Val Acc: 0.7721 / Change Acc: 0.1455\n",
            "[9/200] Train Loss: 0.4340 / Val Loss: 0.5621 / Val Acc: 0.7704 / Change Acc: 0.1818\n",
            "[10/200] Train Loss: 0.4295 / Val Loss: 0.5643 / Val Acc: 0.7636 / Change Acc: 0.1636\n",
            "[11/200] Train Loss: 0.4238 / Val Loss: 0.5751 / Val Acc: 0.7568 / Change Acc: 0.1273\n",
            "[12/200] Train Loss: 0.4242 / Val Loss: 0.5624 / Val Acc: 0.7619 / Change Acc: 0.1818\n",
            "[13/200] Train Loss: 0.4158 / Val Loss: 0.5834 / Val Acc: 0.7517 / Change Acc: 0.1455\n",
            "Early stopping at epoch 14\n",
            "Test Result: test_loss=0.6213 / test_acc=0.3878 / test_change_acc=0.2812\n",
            "Training with lr=0.01, hidden_dim=64, strict_mode=False\n",
            "[1/200] Train Loss: 0.6959 / Val Loss: 0.6593 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.6210 / Val Loss: 0.4944 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.7650 / Val Loss: 1.1464 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[4/200] Train Loss: 1.0544 / Val Loss: 0.6205 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[5/200] Train Loss: 0.7273 / Val Loss: 0.6099 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[6/200] Train Loss: 0.7201 / Val Loss: 0.6103 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[7/200] Train Loss: 0.7073 / Val Loss: 0.6099 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[8/200] Train Loss: 0.7020 / Val Loss: 0.6102 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[9/200] Train Loss: 0.6999 / Val Loss: 0.6101 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[10/200] Train Loss: 0.6992 / Val Loss: 0.6101 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[11/200] Train Loss: 0.6987 / Val Loss: 0.6101 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "Early stopping at epoch 12\n",
            "Test Result: test_loss=0.8875 / test_acc=0.2959 / test_change_acc=0.2812\n",
            "Training with lr=0.01, hidden_dim=64, strict_mode=True\n",
            "[1/200] Train Loss: 0.7078 / Val Loss: 0.6495 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6371 / Val Loss: 0.5458 / Val Acc: 0.5697 / Change Acc: 0.5273\n",
            "[3/200] Train Loss: 0.5069 / Val Loss: 0.8003 / Val Acc: 0.7058 / Change Acc: 0.3455\n",
            "[4/200] Train Loss: 0.5271 / Val Loss: 0.4874 / Val Acc: 0.8027 / Change Acc: 0.1636\n",
            "[5/200] Train Loss: 0.4780 / Val Loss: 0.4565 / Val Acc: 0.8418 / Change Acc: 0.1455\n",
            "[6/200] Train Loss: 0.4547 / Val Loss: 0.5317 / Val Acc: 0.7806 / Change Acc: 0.1273\n",
            "[7/200] Train Loss: 0.4568 / Val Loss: 0.5028 / Val Acc: 0.7823 / Change Acc: 0.1273\n",
            "[8/200] Train Loss: 0.4481 / Val Loss: 0.5157 / Val Acc: 0.7636 / Change Acc: 0.2000\n",
            "[9/200] Train Loss: 0.4499 / Val Loss: 0.5354 / Val Acc: 0.7653 / Change Acc: 0.1455\n",
            "[10/200] Train Loss: 0.4482 / Val Loss: 0.4153 / Val Acc: 0.7585 / Change Acc: 0.3818\n",
            "[11/200] Train Loss: 0.4442 / Val Loss: 0.5231 / Val Acc: 0.7568 / Change Acc: 0.1273\n",
            "[12/200] Train Loss: 0.4482 / Val Loss: 0.4154 / Val Acc: 0.7449 / Change Acc: 0.4545\n",
            "[13/200] Train Loss: 0.4532 / Val Loss: 0.4934 / Val Acc: 0.7857 / Change Acc: 0.1273\n",
            "[14/200] Train Loss: 0.4508 / Val Loss: 0.4358 / Val Acc: 0.8265 / Change Acc: 0.2364\n",
            "[15/200] Train Loss: 0.4491 / Val Loss: 0.4967 / Val Acc: 0.7789 / Change Acc: 0.1091\n",
            "[16/200] Train Loss: 0.4369 / Val Loss: 0.4677 / Val Acc: 0.7993 / Change Acc: 0.1091\n",
            "[17/200] Train Loss: 0.4277 / Val Loss: 0.5742 / Val Acc: 0.7602 / Change Acc: 0.2000\n",
            "[18/200] Train Loss: 0.4243 / Val Loss: 0.4200 / Val Acc: 0.7432 / Change Acc: 0.3091\n",
            "[19/200] Train Loss: 0.4079 / Val Loss: 0.6412 / Val Acc: 0.7279 / Change Acc: 0.3636\n",
            "Early stopping at epoch 20\n",
            "Test Result: test_loss=0.5585 / test_acc=0.2985 / test_change_acc=0.4375\n",
            "Training with lr=0.01, hidden_dim=128, strict_mode=False\n",
            "[1/200] Train Loss: 0.7128 / Val Loss: 1.3188 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 1.0658 / Val Loss: 0.6085 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.7234 / Val Loss: 0.6055 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[4/200] Train Loss: 0.7613 / Val Loss: 0.6614 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[5/200] Train Loss: 0.8604 / Val Loss: 0.6338 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[6/200] Train Loss: 0.7609 / Val Loss: 1.0128 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[7/200] Train Loss: 0.7957 / Val Loss: 1.2019 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[8/200] Train Loss: 1.1404 / Val Loss: 0.6636 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[9/200] Train Loss: 0.8864 / Val Loss: 0.6226 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[10/200] Train Loss: 0.8421 / Val Loss: 0.6083 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[11/200] Train Loss: 0.8081 / Val Loss: 0.6071 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[12/200] Train Loss: 0.7991 / Val Loss: 0.6065 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "Early stopping at epoch 13\n",
            "Test Result: test_loss=0.9873 / test_acc=0.2959 / test_change_acc=0.2812\n",
            "Training with lr=0.01, hidden_dim=128, strict_mode=True\n",
            "[1/200] Train Loss: 0.7893 / Val Loss: 0.6182 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6772 / Val Loss: 0.6113 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[3/200] Train Loss: 0.6746 / Val Loss: 0.6096 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[4/200] Train Loss: 0.6725 / Val Loss: 0.6102 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[5/200] Train Loss: 0.6718 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[6/200] Train Loss: 0.6718 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[7/200] Train Loss: 0.6700 / Val Loss: 0.6072 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[8/200] Train Loss: 0.6794 / Val Loss: 0.6103 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[9/200] Train Loss: 0.6755 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[10/200] Train Loss: 0.6717 / Val Loss: 0.6061 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[11/200] Train Loss: 0.6984 / Val Loss: 0.6123 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[12/200] Train Loss: 0.6869 / Val Loss: 0.6103 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[13/200] Train Loss: 0.6852 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[14/200] Train Loss: 0.6839 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[15/200] Train Loss: 0.6829 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[16/200] Train Loss: 0.6823 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[17/200] Train Loss: 0.6818 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[18/200] Train Loss: 0.6814 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[19/200] Train Loss: 0.6791 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "Early stopping at epoch 20\n",
            "Test Result: test_loss=0.8874 / test_acc=0.7041 / test_change_acc=0.7188\n",
            "Training with lr=0.001, hidden_dim=32, strict_mode=False\n",
            "[1/200] Train Loss: 0.6745 / Val Loss: 0.6555 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.6362 / Val Loss: 0.5845 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.5674 / Val Loss: 0.5098 / Val Acc: 0.7024 / Change Acc: 0.3273\n",
            "[4/200] Train Loss: 0.5377 / Val Loss: 0.4935 / Val Acc: 0.7296 / Change Acc: 0.2364\n",
            "[5/200] Train Loss: 0.5135 / Val Loss: 0.4900 / Val Acc: 0.7313 / Change Acc: 0.2364\n",
            "[6/200] Train Loss: 0.4936 / Val Loss: 0.4853 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[7/200] Train Loss: 0.4746 / Val Loss: 0.4796 / Val Acc: 0.7296 / Change Acc: 0.2545\n",
            "[8/200] Train Loss: 0.4600 / Val Loss: 0.4750 / Val Acc: 0.7262 / Change Acc: 0.2545\n",
            "[9/200] Train Loss: 0.4507 / Val Loss: 0.4714 / Val Acc: 0.7262 / Change Acc: 0.2545\n",
            "[10/200] Train Loss: 0.4446 / Val Loss: 0.4682 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[11/200] Train Loss: 0.4400 / Val Loss: 0.4655 / Val Acc: 0.7279 / Change Acc: 0.2364\n",
            "[12/200] Train Loss: 0.4365 / Val Loss: 0.4632 / Val Acc: 0.7296 / Change Acc: 0.2364\n",
            "[13/200] Train Loss: 0.4336 / Val Loss: 0.4613 / Val Acc: 0.7296 / Change Acc: 0.2364\n",
            "[14/200] Train Loss: 0.4312 / Val Loss: 0.4605 / Val Acc: 0.7296 / Change Acc: 0.2364\n",
            "[15/200] Train Loss: 0.4291 / Val Loss: 0.4597 / Val Acc: 0.7330 / Change Acc: 0.2364\n",
            "[16/200] Train Loss: 0.4273 / Val Loss: 0.4594 / Val Acc: 0.7347 / Change Acc: 0.2364\n",
            "[17/200] Train Loss: 0.4258 / Val Loss: 0.4590 / Val Acc: 0.7347 / Change Acc: 0.2364\n",
            "[18/200] Train Loss: 0.4245 / Val Loss: 0.4588 / Val Acc: 0.7347 / Change Acc: 0.2182\n",
            "[19/200] Train Loss: 0.4233 / Val Loss: 0.4587 / Val Acc: 0.7347 / Change Acc: 0.2182\n",
            "[20/200] Train Loss: 0.4223 / Val Loss: 0.4587 / Val Acc: 0.7364 / Change Acc: 0.2182\n",
            "[21/200] Train Loss: 0.4214 / Val Loss: 0.4588 / Val Acc: 0.7381 / Change Acc: 0.2182\n",
            "[22/200] Train Loss: 0.4205 / Val Loss: 0.4590 / Val Acc: 0.7381 / Change Acc: 0.2182\n",
            "[23/200] Train Loss: 0.4198 / Val Loss: 0.4592 / Val Acc: 0.7381 / Change Acc: 0.2182\n",
            "[24/200] Train Loss: 0.4191 / Val Loss: 0.4595 / Val Acc: 0.7381 / Change Acc: 0.2182\n",
            "[25/200] Train Loss: 0.4184 / Val Loss: 0.4598 / Val Acc: 0.7381 / Change Acc: 0.2182\n",
            "[26/200] Train Loss: 0.4178 / Val Loss: 0.4602 / Val Acc: 0.7398 / Change Acc: 0.2182\n",
            "[27/200] Train Loss: 0.4172 / Val Loss: 0.4606 / Val Acc: 0.7415 / Change Acc: 0.2182\n",
            "[28/200] Train Loss: 0.4167 / Val Loss: 0.4611 / Val Acc: 0.7415 / Change Acc: 0.2182\n",
            "Early stopping at epoch 29\n",
            "Test Result: test_loss=0.5000 / test_acc=0.7653 / test_change_acc=0.5000\n",
            "Training with lr=0.001, hidden_dim=32, strict_mode=True\n",
            "[1/200] Train Loss: 0.6767 / Val Loss: 0.6596 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6486 / Val Loss: 0.6101 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[3/200] Train Loss: 0.5814 / Val Loss: 0.5112 / Val Acc: 0.7925 / Change Acc: 0.2545\n",
            "[4/200] Train Loss: 0.5446 / Val Loss: 0.4894 / Val Acc: 0.6888 / Change Acc: 0.4727\n",
            "[5/200] Train Loss: 0.5145 / Val Loss: 0.4815 / Val Acc: 0.7415 / Change Acc: 0.4727\n",
            "[6/200] Train Loss: 0.4900 / Val Loss: 0.4747 / Val Acc: 0.7636 / Change Acc: 0.4000\n",
            "[7/200] Train Loss: 0.4686 / Val Loss: 0.4687 / Val Acc: 0.8010 / Change Acc: 0.3455\n",
            "[8/200] Train Loss: 0.4554 / Val Loss: 0.4650 / Val Acc: 0.8299 / Change Acc: 0.2000\n",
            "[9/200] Train Loss: 0.4476 / Val Loss: 0.4620 / Val Acc: 0.8384 / Change Acc: 0.1455\n",
            "[10/200] Train Loss: 0.4421 / Val Loss: 0.4595 / Val Acc: 0.8418 / Change Acc: 0.1455\n",
            "[11/200] Train Loss: 0.4379 / Val Loss: 0.4572 / Val Acc: 0.8401 / Change Acc: 0.1455\n",
            "[12/200] Train Loss: 0.4346 / Val Loss: 0.4552 / Val Acc: 0.8384 / Change Acc: 0.1455\n",
            "[13/200] Train Loss: 0.4319 / Val Loss: 0.4535 / Val Acc: 0.8299 / Change Acc: 0.1455\n",
            "[14/200] Train Loss: 0.4296 / Val Loss: 0.4521 / Val Acc: 0.8299 / Change Acc: 0.1455\n",
            "[15/200] Train Loss: 0.4277 / Val Loss: 0.4508 / Val Acc: 0.8282 / Change Acc: 0.1636\n",
            "[16/200] Train Loss: 0.4260 / Val Loss: 0.4499 / Val Acc: 0.8248 / Change Acc: 0.1636\n",
            "[17/200] Train Loss: 0.4245 / Val Loss: 0.4491 / Val Acc: 0.8197 / Change Acc: 0.1636\n",
            "[18/200] Train Loss: 0.4231 / Val Loss: 0.4485 / Val Acc: 0.8163 / Change Acc: 0.1636\n",
            "[19/200] Train Loss: 0.4219 / Val Loss: 0.4480 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "[20/200] Train Loss: 0.4208 / Val Loss: 0.4476 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[21/200] Train Loss: 0.4197 / Val Loss: 0.4473 / Val Acc: 0.8129 / Change Acc: 0.1818\n",
            "[22/200] Train Loss: 0.4187 / Val Loss: 0.4472 / Val Acc: 0.8129 / Change Acc: 0.1818\n",
            "[23/200] Train Loss: 0.4177 / Val Loss: 0.4472 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[24/200] Train Loss: 0.4168 / Val Loss: 0.4472 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[25/200] Train Loss: 0.4158 / Val Loss: 0.4474 / Val Acc: 0.8146 / Change Acc: 0.2000\n",
            "[26/200] Train Loss: 0.4150 / Val Loss: 0.4476 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[27/200] Train Loss: 0.4141 / Val Loss: 0.4481 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[28/200] Train Loss: 0.4133 / Val Loss: 0.4485 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[29/200] Train Loss: 0.4125 / Val Loss: 0.4491 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[30/200] Train Loss: 0.4118 / Val Loss: 0.4496 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[31/200] Train Loss: 0.4110 / Val Loss: 0.4502 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[32/200] Train Loss: 0.4103 / Val Loss: 0.4509 / Val Acc: 0.8044 / Change Acc: 0.2000\n",
            "Early stopping at epoch 33\n",
            "Test Result: test_loss=0.5049 / test_acc=0.6607 / test_change_acc=0.4062\n",
            "Training with lr=0.001, hidden_dim=64, strict_mode=False\n",
            "[1/200] Train Loss: 0.6670 / Val Loss: 0.6350 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.5966 / Val Loss: 0.5188 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.5568 / Val Loss: 0.5002 / Val Acc: 0.7330 / Change Acc: 0.2364\n",
            "[4/200] Train Loss: 0.5041 / Val Loss: 0.4826 / Val Acc: 0.7228 / Change Acc: 0.2545\n",
            "[5/200] Train Loss: 0.4697 / Val Loss: 0.4760 / Val Acc: 0.7075 / Change Acc: 0.2727\n",
            "[6/200] Train Loss: 0.4529 / Val Loss: 0.4752 / Val Acc: 0.7160 / Change Acc: 0.3273\n",
            "[7/200] Train Loss: 0.4449 / Val Loss: 0.4719 / Val Acc: 0.7126 / Change Acc: 0.3091\n",
            "[8/200] Train Loss: 0.4395 / Val Loss: 0.4671 / Val Acc: 0.7177 / Change Acc: 0.2727\n",
            "[9/200] Train Loss: 0.4353 / Val Loss: 0.4632 / Val Acc: 0.7194 / Change Acc: 0.2727\n",
            "[10/200] Train Loss: 0.4323 / Val Loss: 0.4598 / Val Acc: 0.7228 / Change Acc: 0.2727\n",
            "[11/200] Train Loss: 0.4299 / Val Loss: 0.4573 / Val Acc: 0.7245 / Change Acc: 0.2545\n",
            "[12/200] Train Loss: 0.4280 / Val Loss: 0.4551 / Val Acc: 0.7262 / Change Acc: 0.2545\n",
            "[13/200] Train Loss: 0.4264 / Val Loss: 0.4530 / Val Acc: 0.7262 / Change Acc: 0.2364\n",
            "[14/200] Train Loss: 0.4252 / Val Loss: 0.4510 / Val Acc: 0.7279 / Change Acc: 0.2364\n",
            "[15/200] Train Loss: 0.4240 / Val Loss: 0.4491 / Val Acc: 0.7330 / Change Acc: 0.2182\n",
            "[16/200] Train Loss: 0.4230 / Val Loss: 0.4473 / Val Acc: 0.7347 / Change Acc: 0.2000\n",
            "[17/200] Train Loss: 0.4221 / Val Loss: 0.4456 / Val Acc: 0.7381 / Change Acc: 0.2000\n",
            "[18/200] Train Loss: 0.4212 / Val Loss: 0.4443 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[19/200] Train Loss: 0.4204 / Val Loss: 0.4430 / Val Acc: 0.7398 / Change Acc: 0.1636\n",
            "[20/200] Train Loss: 0.4196 / Val Loss: 0.4419 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[21/200] Train Loss: 0.4189 / Val Loss: 0.4411 / Val Acc: 0.7551 / Change Acc: 0.1636\n",
            "[22/200] Train Loss: 0.4182 / Val Loss: 0.4406 / Val Acc: 0.7585 / Change Acc: 0.1636\n",
            "[23/200] Train Loss: 0.4175 / Val Loss: 0.4401 / Val Acc: 0.7602 / Change Acc: 0.1636\n",
            "[24/200] Train Loss: 0.4167 / Val Loss: 0.4400 / Val Acc: 0.7636 / Change Acc: 0.1636\n",
            "[25/200] Train Loss: 0.4161 / Val Loss: 0.4398 / Val Acc: 0.7636 / Change Acc: 0.1636\n",
            "[26/200] Train Loss: 0.4154 / Val Loss: 0.4397 / Val Acc: 0.7653 / Change Acc: 0.1636\n",
            "[27/200] Train Loss: 0.4147 / Val Loss: 0.4399 / Val Acc: 0.7670 / Change Acc: 0.1455\n",
            "[28/200] Train Loss: 0.4140 / Val Loss: 0.4399 / Val Acc: 0.7721 / Change Acc: 0.1455\n",
            "[29/200] Train Loss: 0.4132 / Val Loss: 0.4402 / Val Acc: 0.7721 / Change Acc: 0.1455\n",
            "[30/200] Train Loss: 0.4125 / Val Loss: 0.4406 / Val Acc: 0.7721 / Change Acc: 0.1273\n",
            "[31/200] Train Loss: 0.4118 / Val Loss: 0.4407 / Val Acc: 0.7721 / Change Acc: 0.1273\n",
            "[32/200] Train Loss: 0.4109 / Val Loss: 0.4413 / Val Acc: 0.7704 / Change Acc: 0.1273\n",
            "[33/200] Train Loss: 0.4102 / Val Loss: 0.4416 / Val Acc: 0.7670 / Change Acc: 0.1273\n",
            "[34/200] Train Loss: 0.4093 / Val Loss: 0.4422 / Val Acc: 0.7670 / Change Acc: 0.1273\n",
            "[35/200] Train Loss: 0.4085 / Val Loss: 0.4429 / Val Acc: 0.7670 / Change Acc: 0.1273\n",
            "Early stopping at epoch 36\n",
            "Test Result: test_loss=0.5161 / test_acc=0.7628 / test_change_acc=0.5312\n",
            "Training with lr=0.001, hidden_dim=64, strict_mode=True\n",
            "[1/200] Train Loss: 0.6824 / Val Loss: 0.6530 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6114 / Val Loss: 0.5229 / Val Acc: 0.8129 / Change Acc: 0.2727\n",
            "[3/200] Train Loss: 0.5670 / Val Loss: 0.5047 / Val Acc: 0.6122 / Change Acc: 0.6364\n",
            "[4/200] Train Loss: 0.5222 / Val Loss: 0.4890 / Val Acc: 0.7143 / Change Acc: 0.4364\n",
            "[5/200] Train Loss: 0.4844 / Val Loss: 0.4786 / Val Acc: 0.8010 / Change Acc: 0.4364\n",
            "[6/200] Train Loss: 0.4604 / Val Loss: 0.4813 / Val Acc: 0.8486 / Change Acc: 0.0364\n",
            "[7/200] Train Loss: 0.4506 / Val Loss: 0.4804 / Val Acc: 0.8486 / Change Acc: 0.0545\n",
            "[8/200] Train Loss: 0.4437 / Val Loss: 0.4766 / Val Acc: 0.8384 / Change Acc: 0.0727\n",
            "[9/200] Train Loss: 0.4384 / Val Loss: 0.4727 / Val Acc: 0.8333 / Change Acc: 0.0909\n",
            "[10/200] Train Loss: 0.4343 / Val Loss: 0.4700 / Val Acc: 0.8299 / Change Acc: 0.1273\n",
            "[11/200] Train Loss: 0.4313 / Val Loss: 0.4679 / Val Acc: 0.8248 / Change Acc: 0.1273\n",
            "[12/200] Train Loss: 0.4289 / Val Loss: 0.4661 / Val Acc: 0.8214 / Change Acc: 0.1273\n",
            "[13/200] Train Loss: 0.4270 / Val Loss: 0.4643 / Val Acc: 0.8214 / Change Acc: 0.1455\n",
            "[14/200] Train Loss: 0.4254 / Val Loss: 0.4626 / Val Acc: 0.8163 / Change Acc: 0.1455\n",
            "[15/200] Train Loss: 0.4240 / Val Loss: 0.4608 / Val Acc: 0.8180 / Change Acc: 0.1455\n",
            "[16/200] Train Loss: 0.4227 / Val Loss: 0.4593 / Val Acc: 0.8180 / Change Acc: 0.1455\n",
            "[17/200] Train Loss: 0.4216 / Val Loss: 0.4580 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "[18/200] Train Loss: 0.4206 / Val Loss: 0.4568 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "[19/200] Train Loss: 0.4196 / Val Loss: 0.4559 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[20/200] Train Loss: 0.4187 / Val Loss: 0.4553 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[21/200] Train Loss: 0.4179 / Val Loss: 0.4548 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[22/200] Train Loss: 0.4171 / Val Loss: 0.4546 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[23/200] Train Loss: 0.4163 / Val Loss: 0.4544 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[24/200] Train Loss: 0.4155 / Val Loss: 0.4545 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[25/200] Train Loss: 0.4148 / Val Loss: 0.4546 / Val Acc: 0.8044 / Change Acc: 0.2182\n",
            "[26/200] Train Loss: 0.4140 / Val Loss: 0.4550 / Val Acc: 0.8061 / Change Acc: 0.2364\n",
            "[27/200] Train Loss: 0.4133 / Val Loss: 0.4554 / Val Acc: 0.8061 / Change Acc: 0.2364\n",
            "[28/200] Train Loss: 0.4125 / Val Loss: 0.4556 / Val Acc: 0.8061 / Change Acc: 0.2364\n",
            "[29/200] Train Loss: 0.4117 / Val Loss: 0.4563 / Val Acc: 0.8095 / Change Acc: 0.2364\n",
            "[30/200] Train Loss: 0.4110 / Val Loss: 0.4568 / Val Acc: 0.8078 / Change Acc: 0.2364\n",
            "[31/200] Train Loss: 0.4102 / Val Loss: 0.4573 / Val Acc: 0.8112 / Change Acc: 0.2364\n",
            "[32/200] Train Loss: 0.4094 / Val Loss: 0.4579 / Val Acc: 0.8112 / Change Acc: 0.2364\n",
            "Early stopping at epoch 33\n",
            "Test Result: test_loss=0.5058 / test_acc=0.6454 / test_change_acc=0.5000\n",
            "Training with lr=0.001, hidden_dim=128, strict_mode=False\n",
            "[1/200] Train Loss: 0.6771 / Val Loss: 0.6260 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.5902 / Val Loss: 0.5053 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[3/200] Train Loss: 0.5667 / Val Loss: 0.5679 / Val Acc: 0.7670 / Change Acc: 0.2727\n",
            "[4/200] Train Loss: 0.4799 / Val Loss: 0.4602 / Val Acc: 0.7534 / Change Acc: 0.2364\n",
            "[5/200] Train Loss: 0.4514 / Val Loss: 0.4745 / Val Acc: 0.7143 / Change Acc: 0.3273\n",
            "[6/200] Train Loss: 0.4443 / Val Loss: 0.4634 / Val Acc: 0.7194 / Change Acc: 0.2727\n",
            "[7/200] Train Loss: 0.4393 / Val Loss: 0.4582 / Val Acc: 0.7279 / Change Acc: 0.2727\n",
            "[8/200] Train Loss: 0.4358 / Val Loss: 0.4537 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[9/200] Train Loss: 0.4334 / Val Loss: 0.4505 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[10/200] Train Loss: 0.4315 / Val Loss: 0.4477 / Val Acc: 0.7398 / Change Acc: 0.2364\n",
            "[11/200] Train Loss: 0.4301 / Val Loss: 0.4450 / Val Acc: 0.7466 / Change Acc: 0.2364\n",
            "[12/200] Train Loss: 0.4289 / Val Loss: 0.4427 / Val Acc: 0.7449 / Change Acc: 0.2182\n",
            "[13/200] Train Loss: 0.4278 / Val Loss: 0.4406 / Val Acc: 0.7517 / Change Acc: 0.2182\n",
            "[14/200] Train Loss: 0.4269 / Val Loss: 0.4391 / Val Acc: 0.7500 / Change Acc: 0.2000\n",
            "[15/200] Train Loss: 0.4261 / Val Loss: 0.4378 / Val Acc: 0.7534 / Change Acc: 0.2000\n",
            "[16/200] Train Loss: 0.4254 / Val Loss: 0.4369 / Val Acc: 0.7551 / Change Acc: 0.2000\n",
            "[17/200] Train Loss: 0.4246 / Val Loss: 0.4362 / Val Acc: 0.7602 / Change Acc: 0.2000\n",
            "[18/200] Train Loss: 0.4238 / Val Loss: 0.4358 / Val Acc: 0.7636 / Change Acc: 0.2000\n",
            "[19/200] Train Loss: 0.4230 / Val Loss: 0.4358 / Val Acc: 0.7670 / Change Acc: 0.1818\n",
            "[20/200] Train Loss: 0.4222 / Val Loss: 0.4361 / Val Acc: 0.7670 / Change Acc: 0.1818\n",
            "[21/200] Train Loss: 0.4213 / Val Loss: 0.4363 / Val Acc: 0.7687 / Change Acc: 0.1818\n",
            "[22/200] Train Loss: 0.4204 / Val Loss: 0.4370 / Val Acc: 0.7704 / Change Acc: 0.1636\n",
            "[23/200] Train Loss: 0.4195 / Val Loss: 0.4378 / Val Acc: 0.7704 / Change Acc: 0.1636\n",
            "[24/200] Train Loss: 0.4184 / Val Loss: 0.4388 / Val Acc: 0.7738 / Change Acc: 0.1636\n",
            "[25/200] Train Loss: 0.4173 / Val Loss: 0.4399 / Val Acc: 0.7755 / Change Acc: 0.1636\n",
            "[26/200] Train Loss: 0.4161 / Val Loss: 0.4412 / Val Acc: 0.7738 / Change Acc: 0.1636\n",
            "[27/200] Train Loss: 0.4148 / Val Loss: 0.4424 / Val Acc: 0.7721 / Change Acc: 0.1455\n",
            "[28/200] Train Loss: 0.4134 / Val Loss: 0.4436 / Val Acc: 0.7670 / Change Acc: 0.1455\n",
            "Early stopping at epoch 29\n",
            "Test Result: test_loss=0.5121 / test_acc=0.7704 / test_change_acc=0.5625\n",
            "Training with lr=0.001, hidden_dim=128, strict_mode=True\n",
            "[1/200] Train Loss: 0.6752 / Val Loss: 0.6310 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.5885 / Val Loss: 0.4910 / Val Acc: 0.7279 / Change Acc: 0.4182\n",
            "[3/200] Train Loss: 0.5821 / Val Loss: 0.5734 / Val Acc: 0.2738 / Change Acc: 0.7273\n",
            "[4/200] Train Loss: 0.4817 / Val Loss: 0.4590 / Val Acc: 0.7755 / Change Acc: 0.4182\n",
            "[5/200] Train Loss: 0.4525 / Val Loss: 0.4716 / Val Acc: 0.8571 / Change Acc: 0.1273\n",
            "[6/200] Train Loss: 0.4442 / Val Loss: 0.4645 / Val Acc: 0.8503 / Change Acc: 0.1091\n",
            "[7/200] Train Loss: 0.4393 / Val Loss: 0.4600 / Val Acc: 0.8367 / Change Acc: 0.1091\n",
            "[8/200] Train Loss: 0.4356 / Val Loss: 0.4566 / Val Acc: 0.8350 / Change Acc: 0.1091\n",
            "[9/200] Train Loss: 0.4331 / Val Loss: 0.4534 / Val Acc: 0.8282 / Change Acc: 0.1273\n",
            "[10/200] Train Loss: 0.4312 / Val Loss: 0.4505 / Val Acc: 0.8265 / Change Acc: 0.1273\n",
            "[11/200] Train Loss: 0.4297 / Val Loss: 0.4477 / Val Acc: 0.8231 / Change Acc: 0.1273\n",
            "[12/200] Train Loss: 0.4284 / Val Loss: 0.4453 / Val Acc: 0.8163 / Change Acc: 0.1455\n",
            "[13/200] Train Loss: 0.4272 / Val Loss: 0.4434 / Val Acc: 0.8078 / Change Acc: 0.1455\n",
            "[14/200] Train Loss: 0.4262 / Val Loss: 0.4419 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[15/200] Train Loss: 0.4252 / Val Loss: 0.4411 / Val Acc: 0.8010 / Change Acc: 0.1818\n",
            "[16/200] Train Loss: 0.4243 / Val Loss: 0.4406 / Val Acc: 0.8010 / Change Acc: 0.1818\n",
            "[17/200] Train Loss: 0.4233 / Val Loss: 0.4401 / Val Acc: 0.7993 / Change Acc: 0.1818\n",
            "[18/200] Train Loss: 0.4221 / Val Loss: 0.4397 / Val Acc: 0.7993 / Change Acc: 0.1818\n",
            "[19/200] Train Loss: 0.4211 / Val Loss: 0.4395 / Val Acc: 0.7959 / Change Acc: 0.2000\n",
            "[20/200] Train Loss: 0.4196 / Val Loss: 0.4404 / Val Acc: 0.7925 / Change Acc: 0.2000\n",
            "[21/200] Train Loss: 0.4184 / Val Loss: 0.4415 / Val Acc: 0.7908 / Change Acc: 0.2000\n",
            "[22/200] Train Loss: 0.4170 / Val Loss: 0.4430 / Val Acc: 0.7874 / Change Acc: 0.2000\n",
            "[23/200] Train Loss: 0.4157 / Val Loss: 0.4446 / Val Acc: 0.7874 / Change Acc: 0.2000\n",
            "[24/200] Train Loss: 0.4141 / Val Loss: 0.4468 / Val Acc: 0.7857 / Change Acc: 0.2000\n",
            "[25/200] Train Loss: 0.4127 / Val Loss: 0.4485 / Val Acc: 0.7857 / Change Acc: 0.2000\n",
            "[26/200] Train Loss: 0.4111 / Val Loss: 0.4501 / Val Acc: 0.7891 / Change Acc: 0.2000\n",
            "[27/200] Train Loss: 0.4096 / Val Loss: 0.4516 / Val Acc: 0.7891 / Change Acc: 0.2000\n",
            "[28/200] Train Loss: 0.4079 / Val Loss: 0.4524 / Val Acc: 0.7908 / Change Acc: 0.2000\n",
            "Early stopping at epoch 29\n",
            "Test Result: test_loss=0.5057 / test_acc=0.6276 / test_change_acc=0.4688\n",
            "Training with lr=0.0001, hidden_dim=32, strict_mode=False\n",
            "[1/200] Train Loss: 0.6840 / Val Loss: 0.6797 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.6806 / Val Loss: 0.6757 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.6773 / Val Loss: 0.6716 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[4/200] Train Loss: 0.6741 / Val Loss: 0.6676 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[5/200] Train Loss: 0.6707 / Val Loss: 0.6634 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[6/200] Train Loss: 0.6671 / Val Loss: 0.6590 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[7/200] Train Loss: 0.6633 / Val Loss: 0.6542 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[8/200] Train Loss: 0.6590 / Val Loss: 0.6490 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[9/200] Train Loss: 0.6542 / Val Loss: 0.6433 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[10/200] Train Loss: 0.6488 / Val Loss: 0.6369 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[11/200] Train Loss: 0.6427 / Val Loss: 0.6297 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[12/200] Train Loss: 0.6357 / Val Loss: 0.6216 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[13/200] Train Loss: 0.6277 / Val Loss: 0.6125 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[14/200] Train Loss: 0.6186 / Val Loss: 0.6024 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[15/200] Train Loss: 0.6084 / Val Loss: 0.5914 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[16/200] Train Loss: 0.5971 / Val Loss: 0.5796 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[17/200] Train Loss: 0.5851 / Val Loss: 0.5678 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[18/200] Train Loss: 0.5730 / Val Loss: 0.5563 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[19/200] Train Loss: 0.5612 / Val Loss: 0.5460 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[20/200] Train Loss: 0.5506 / Val Loss: 0.5373 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[21/200] Train Loss: 0.5413 / Val Loss: 0.5302 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[22/200] Train Loss: 0.5336 / Val Loss: 0.5246 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[23/200] Train Loss: 0.5273 / Val Loss: 0.5204 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[24/200] Train Loss: 0.5222 / Val Loss: 0.5171 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[25/200] Train Loss: 0.5180 / Val Loss: 0.5147 / Val Acc: 0.7041 / Change Acc: 0.3455\n",
            "[26/200] Train Loss: 0.5145 / Val Loss: 0.5129 / Val Acc: 0.6990 / Change Acc: 0.2909\n",
            "[27/200] Train Loss: 0.5115 / Val Loss: 0.5115 / Val Acc: 0.7041 / Change Acc: 0.2909\n",
            "[28/200] Train Loss: 0.5089 / Val Loss: 0.5104 / Val Acc: 0.7041 / Change Acc: 0.2727\n",
            "[29/200] Train Loss: 0.5066 / Val Loss: 0.5095 / Val Acc: 0.7109 / Change Acc: 0.2727\n",
            "[30/200] Train Loss: 0.5044 / Val Loss: 0.5088 / Val Acc: 0.7109 / Change Acc: 0.2727\n",
            "[31/200] Train Loss: 0.5024 / Val Loss: 0.5083 / Val Acc: 0.7109 / Change Acc: 0.2727\n",
            "[32/200] Train Loss: 0.5005 / Val Loss: 0.5078 / Val Acc: 0.7126 / Change Acc: 0.2727\n",
            "[33/200] Train Loss: 0.4987 / Val Loss: 0.5073 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[34/200] Train Loss: 0.4970 / Val Loss: 0.5069 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[35/200] Train Loss: 0.4952 / Val Loss: 0.5065 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[36/200] Train Loss: 0.4935 / Val Loss: 0.5061 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[37/200] Train Loss: 0.4919 / Val Loss: 0.5057 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[38/200] Train Loss: 0.4902 / Val Loss: 0.5053 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[39/200] Train Loss: 0.4885 / Val Loss: 0.5049 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[40/200] Train Loss: 0.4869 / Val Loss: 0.5045 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[41/200] Train Loss: 0.4853 / Val Loss: 0.5041 / Val Acc: 0.7211 / Change Acc: 0.2545\n",
            "[42/200] Train Loss: 0.4836 / Val Loss: 0.5036 / Val Acc: 0.7211 / Change Acc: 0.2545\n",
            "[43/200] Train Loss: 0.4820 / Val Loss: 0.5032 / Val Acc: 0.7211 / Change Acc: 0.2545\n",
            "[44/200] Train Loss: 0.4804 / Val Loss: 0.5027 / Val Acc: 0.7211 / Change Acc: 0.2545\n",
            "[45/200] Train Loss: 0.4788 / Val Loss: 0.5022 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[46/200] Train Loss: 0.4772 / Val Loss: 0.5017 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[47/200] Train Loss: 0.4756 / Val Loss: 0.5011 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[48/200] Train Loss: 0.4741 / Val Loss: 0.5005 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[49/200] Train Loss: 0.4725 / Val Loss: 0.5000 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[50/200] Train Loss: 0.4710 / Val Loss: 0.4994 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[51/200] Train Loss: 0.4695 / Val Loss: 0.4988 / Val Acc: 0.7194 / Change Acc: 0.2545\n",
            "[52/200] Train Loss: 0.4680 / Val Loss: 0.4982 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[53/200] Train Loss: 0.4665 / Val Loss: 0.4975 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[54/200] Train Loss: 0.4651 / Val Loss: 0.4969 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[55/200] Train Loss: 0.4637 / Val Loss: 0.4963 / Val Acc: 0.7177 / Change Acc: 0.2545\n",
            "[56/200] Train Loss: 0.4623 / Val Loss: 0.4956 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[57/200] Train Loss: 0.4610 / Val Loss: 0.4950 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[58/200] Train Loss: 0.4597 / Val Loss: 0.4943 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[59/200] Train Loss: 0.4584 / Val Loss: 0.4937 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[60/200] Train Loss: 0.4572 / Val Loss: 0.4930 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[61/200] Train Loss: 0.4560 / Val Loss: 0.4924 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[62/200] Train Loss: 0.4549 / Val Loss: 0.4918 / Val Acc: 0.7160 / Change Acc: 0.2545\n",
            "[63/200] Train Loss: 0.4538 / Val Loss: 0.4912 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[64/200] Train Loss: 0.4528 / Val Loss: 0.4906 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[65/200] Train Loss: 0.4518 / Val Loss: 0.4900 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[66/200] Train Loss: 0.4508 / Val Loss: 0.4894 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[67/200] Train Loss: 0.4499 / Val Loss: 0.4888 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[68/200] Train Loss: 0.4490 / Val Loss: 0.4883 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[69/200] Train Loss: 0.4481 / Val Loss: 0.4877 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[70/200] Train Loss: 0.4473 / Val Loss: 0.4872 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[71/200] Train Loss: 0.4465 / Val Loss: 0.4866 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[72/200] Train Loss: 0.4458 / Val Loss: 0.4861 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[73/200] Train Loss: 0.4450 / Val Loss: 0.4856 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[74/200] Train Loss: 0.4443 / Val Loss: 0.4852 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[75/200] Train Loss: 0.4437 / Val Loss: 0.4847 / Val Acc: 0.7143 / Change Acc: 0.2545\n",
            "[76/200] Train Loss: 0.4430 / Val Loss: 0.4842 / Val Acc: 0.7126 / Change Acc: 0.2545\n",
            "[77/200] Train Loss: 0.4424 / Val Loss: 0.4838 / Val Acc: 0.7126 / Change Acc: 0.2545\n",
            "[78/200] Train Loss: 0.4418 / Val Loss: 0.4834 / Val Acc: 0.7126 / Change Acc: 0.2545\n",
            "[79/200] Train Loss: 0.4412 / Val Loss: 0.4829 / Val Acc: 0.7126 / Change Acc: 0.2545\n",
            "[80/200] Train Loss: 0.4407 / Val Loss: 0.4825 / Val Acc: 0.7109 / Change Acc: 0.2364\n",
            "[81/200] Train Loss: 0.4402 / Val Loss: 0.4821 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[82/200] Train Loss: 0.4396 / Val Loss: 0.4817 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[83/200] Train Loss: 0.4391 / Val Loss: 0.4814 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[84/200] Train Loss: 0.4387 / Val Loss: 0.4810 / Val Acc: 0.7109 / Change Acc: 0.2364\n",
            "[85/200] Train Loss: 0.4382 / Val Loss: 0.4806 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[86/200] Train Loss: 0.4378 / Val Loss: 0.4803 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[87/200] Train Loss: 0.4373 / Val Loss: 0.4799 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[88/200] Train Loss: 0.4369 / Val Loss: 0.4796 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[89/200] Train Loss: 0.4365 / Val Loss: 0.4793 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[90/200] Train Loss: 0.4361 / Val Loss: 0.4789 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[91/200] Train Loss: 0.4357 / Val Loss: 0.4786 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[92/200] Train Loss: 0.4353 / Val Loss: 0.4783 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[93/200] Train Loss: 0.4350 / Val Loss: 0.4780 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[94/200] Train Loss: 0.4346 / Val Loss: 0.4778 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[95/200] Train Loss: 0.4342 / Val Loss: 0.4775 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[96/200] Train Loss: 0.4339 / Val Loss: 0.4772 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[97/200] Train Loss: 0.4336 / Val Loss: 0.4769 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[98/200] Train Loss: 0.4332 / Val Loss: 0.4767 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[99/200] Train Loss: 0.4329 / Val Loss: 0.4764 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[100/200] Train Loss: 0.4326 / Val Loss: 0.4762 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[101/200] Train Loss: 0.4323 / Val Loss: 0.4759 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[102/200] Train Loss: 0.4320 / Val Loss: 0.4757 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[103/200] Train Loss: 0.4317 / Val Loss: 0.4754 / Val Acc: 0.7126 / Change Acc: 0.2364\n",
            "[104/200] Train Loss: 0.4314 / Val Loss: 0.4752 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[105/200] Train Loss: 0.4312 / Val Loss: 0.4750 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[106/200] Train Loss: 0.4309 / Val Loss: 0.4747 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[107/200] Train Loss: 0.4306 / Val Loss: 0.4745 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[108/200] Train Loss: 0.4303 / Val Loss: 0.4743 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[109/200] Train Loss: 0.4301 / Val Loss: 0.4741 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[110/200] Train Loss: 0.4298 / Val Loss: 0.4739 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[111/200] Train Loss: 0.4296 / Val Loss: 0.4737 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[112/200] Train Loss: 0.4293 / Val Loss: 0.4735 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[113/200] Train Loss: 0.4291 / Val Loss: 0.4733 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[114/200] Train Loss: 0.4288 / Val Loss: 0.4731 / Val Acc: 0.7143 / Change Acc: 0.2364\n",
            "[115/200] Train Loss: 0.4286 / Val Loss: 0.4729 / Val Acc: 0.7160 / Change Acc: 0.2364\n",
            "[116/200] Train Loss: 0.4284 / Val Loss: 0.4727 / Val Acc: 0.7177 / Change Acc: 0.2364\n",
            "[117/200] Train Loss: 0.4281 / Val Loss: 0.4725 / Val Acc: 0.7177 / Change Acc: 0.2364\n",
            "[118/200] Train Loss: 0.4279 / Val Loss: 0.4723 / Val Acc: 0.7177 / Change Acc: 0.2364\n",
            "[119/200] Train Loss: 0.4277 / Val Loss: 0.4721 / Val Acc: 0.7177 / Change Acc: 0.2364\n",
            "[120/200] Train Loss: 0.4275 / Val Loss: 0.4720 / Val Acc: 0.7194 / Change Acc: 0.2364\n",
            "[121/200] Train Loss: 0.4272 / Val Loss: 0.4718 / Val Acc: 0.7194 / Change Acc: 0.2364\n",
            "[122/200] Train Loss: 0.4270 / Val Loss: 0.4716 / Val Acc: 0.7194 / Change Acc: 0.2364\n",
            "[123/200] Train Loss: 0.4268 / Val Loss: 0.4715 / Val Acc: 0.7194 / Change Acc: 0.2364\n",
            "[124/200] Train Loss: 0.4266 / Val Loss: 0.4713 / Val Acc: 0.7194 / Change Acc: 0.2364\n",
            "[125/200] Train Loss: 0.4264 / Val Loss: 0.4711 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[126/200] Train Loss: 0.4262 / Val Loss: 0.4710 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[127/200] Train Loss: 0.4260 / Val Loss: 0.4708 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[128/200] Train Loss: 0.4258 / Val Loss: 0.4707 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[129/200] Train Loss: 0.4256 / Val Loss: 0.4705 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[130/200] Train Loss: 0.4254 / Val Loss: 0.4704 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[131/200] Train Loss: 0.4252 / Val Loss: 0.4702 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[132/200] Train Loss: 0.4250 / Val Loss: 0.4701 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[133/200] Train Loss: 0.4248 / Val Loss: 0.4699 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[134/200] Train Loss: 0.4247 / Val Loss: 0.4698 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[135/200] Train Loss: 0.4245 / Val Loss: 0.4697 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[136/200] Train Loss: 0.4243 / Val Loss: 0.4695 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[137/200] Train Loss: 0.4241 / Val Loss: 0.4694 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[138/200] Train Loss: 0.4240 / Val Loss: 0.4693 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[139/200] Train Loss: 0.4238 / Val Loss: 0.4691 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[140/200] Train Loss: 0.4236 / Val Loss: 0.4690 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[141/200] Train Loss: 0.4234 / Val Loss: 0.4689 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[142/200] Train Loss: 0.4233 / Val Loss: 0.4688 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[143/200] Train Loss: 0.4231 / Val Loss: 0.4687 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[144/200] Train Loss: 0.4230 / Val Loss: 0.4686 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[145/200] Train Loss: 0.4228 / Val Loss: 0.4685 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[146/200] Train Loss: 0.4226 / Val Loss: 0.4683 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[147/200] Train Loss: 0.4225 / Val Loss: 0.4682 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[148/200] Train Loss: 0.4223 / Val Loss: 0.4681 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[149/200] Train Loss: 0.4222 / Val Loss: 0.4680 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[150/200] Train Loss: 0.4220 / Val Loss: 0.4679 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[151/200] Train Loss: 0.4219 / Val Loss: 0.4678 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[152/200] Train Loss: 0.4217 / Val Loss: 0.4677 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[153/200] Train Loss: 0.4216 / Val Loss: 0.4676 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[154/200] Train Loss: 0.4214 / Val Loss: 0.4675 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[155/200] Train Loss: 0.4213 / Val Loss: 0.4674 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[156/200] Train Loss: 0.4212 / Val Loss: 0.4673 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[157/200] Train Loss: 0.4210 / Val Loss: 0.4672 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[158/200] Train Loss: 0.4209 / Val Loss: 0.4672 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[159/200] Train Loss: 0.4207 / Val Loss: 0.4671 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[160/200] Train Loss: 0.4206 / Val Loss: 0.4670 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[161/200] Train Loss: 0.4205 / Val Loss: 0.4669 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[162/200] Train Loss: 0.4203 / Val Loss: 0.4669 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[163/200] Train Loss: 0.4202 / Val Loss: 0.4668 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[164/200] Train Loss: 0.4201 / Val Loss: 0.4667 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[165/200] Train Loss: 0.4199 / Val Loss: 0.4666 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[166/200] Train Loss: 0.4198 / Val Loss: 0.4666 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[167/200] Train Loss: 0.4197 / Val Loss: 0.4665 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[168/200] Train Loss: 0.4196 / Val Loss: 0.4664 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[169/200] Train Loss: 0.4195 / Val Loss: 0.4664 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[170/200] Train Loss: 0.4193 / Val Loss: 0.4663 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[171/200] Train Loss: 0.4192 / Val Loss: 0.4663 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[172/200] Train Loss: 0.4191 / Val Loss: 0.4662 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[173/200] Train Loss: 0.4190 / Val Loss: 0.4661 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[174/200] Train Loss: 0.4189 / Val Loss: 0.4661 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[175/200] Train Loss: 0.4187 / Val Loss: 0.4660 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[176/200] Train Loss: 0.4186 / Val Loss: 0.4660 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[177/200] Train Loss: 0.4185 / Val Loss: 0.4659 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[178/200] Train Loss: 0.4184 / Val Loss: 0.4659 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[179/200] Train Loss: 0.4183 / Val Loss: 0.4658 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[180/200] Train Loss: 0.4182 / Val Loss: 0.4658 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[181/200] Train Loss: 0.4181 / Val Loss: 0.4658 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[182/200] Train Loss: 0.4180 / Val Loss: 0.4657 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[183/200] Train Loss: 0.4179 / Val Loss: 0.4657 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[184/200] Train Loss: 0.4178 / Val Loss: 0.4656 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[185/200] Train Loss: 0.4177 / Val Loss: 0.4656 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[186/200] Train Loss: 0.4176 / Val Loss: 0.4656 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[187/200] Train Loss: 0.4175 / Val Loss: 0.4655 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[188/200] Train Loss: 0.4174 / Val Loss: 0.4655 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[189/200] Train Loss: 0.4173 / Val Loss: 0.4655 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[190/200] Train Loss: 0.4172 / Val Loss: 0.4654 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[191/200] Train Loss: 0.4171 / Val Loss: 0.4654 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[192/200] Train Loss: 0.4170 / Val Loss: 0.4653 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[193/200] Train Loss: 0.4169 / Val Loss: 0.4653 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[194/200] Train Loss: 0.4168 / Val Loss: 0.4653 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[195/200] Train Loss: 0.4167 / Val Loss: 0.4652 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[196/200] Train Loss: 0.4166 / Val Loss: 0.4652 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[197/200] Train Loss: 0.4165 / Val Loss: 0.4652 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[198/200] Train Loss: 0.4164 / Val Loss: 0.4652 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[199/200] Train Loss: 0.4163 / Val Loss: 0.4651 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[200/200] Train Loss: 0.4163 / Val Loss: 0.4651 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "Test Result: test_loss=0.4951 / test_acc=0.7551 / test_change_acc=0.4375\n",
            "Training with lr=0.0001, hidden_dim=32, strict_mode=True\n",
            "[1/200] Train Loss: 0.6699 / Val Loss: 0.6606 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6676 / Val Loss: 0.6581 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[3/200] Train Loss: 0.6656 / Val Loss: 0.6556 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[4/200] Train Loss: 0.6635 / Val Loss: 0.6530 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[5/200] Train Loss: 0.6614 / Val Loss: 0.6504 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[6/200] Train Loss: 0.6591 / Val Loss: 0.6476 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[7/200] Train Loss: 0.6566 / Val Loss: 0.6446 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[8/200] Train Loss: 0.6539 / Val Loss: 0.6414 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[9/200] Train Loss: 0.6508 / Val Loss: 0.6378 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[10/200] Train Loss: 0.6474 / Val Loss: 0.6337 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[11/200] Train Loss: 0.6434 / Val Loss: 0.6291 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[12/200] Train Loss: 0.6387 / Val Loss: 0.6238 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[13/200] Train Loss: 0.6332 / Val Loss: 0.6177 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[14/200] Train Loss: 0.6268 / Val Loss: 0.6105 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[15/200] Train Loss: 0.6194 / Val Loss: 0.6022 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[16/200] Train Loss: 0.6107 / Val Loss: 0.5928 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[17/200] Train Loss: 0.6009 / Val Loss: 0.5824 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[18/200] Train Loss: 0.5902 / Val Loss: 0.5714 / Val Acc: 0.5085 / Change Acc: 0.5818\n",
            "[19/200] Train Loss: 0.5790 / Val Loss: 0.5604 / Val Acc: 0.6020 / Change Acc: 0.4727\n",
            "[20/200] Train Loss: 0.5679 / Val Loss: 0.5502 / Val Acc: 0.6582 / Change Acc: 0.4545\n",
            "[21/200] Train Loss: 0.5576 / Val Loss: 0.5413 / Val Acc: 0.7194 / Change Acc: 0.4000\n",
            "[22/200] Train Loss: 0.5484 / Val Loss: 0.5339 / Val Acc: 0.7619 / Change Acc: 0.3273\n",
            "[23/200] Train Loss: 0.5406 / Val Loss: 0.5281 / Val Acc: 0.7908 / Change Acc: 0.2909\n",
            "[24/200] Train Loss: 0.5340 / Val Loss: 0.5236 / Val Acc: 0.8078 / Change Acc: 0.2364\n",
            "[25/200] Train Loss: 0.5285 / Val Loss: 0.5202 / Val Acc: 0.8146 / Change Acc: 0.2182\n",
            "[26/200] Train Loss: 0.5240 / Val Loss: 0.5176 / Val Acc: 0.8146 / Change Acc: 0.2000\n",
            "[27/200] Train Loss: 0.5201 / Val Loss: 0.5158 / Val Acc: 0.8214 / Change Acc: 0.2727\n",
            "[28/200] Train Loss: 0.5168 / Val Loss: 0.5144 / Val Acc: 0.8163 / Change Acc: 0.2364\n",
            "[29/200] Train Loss: 0.5140 / Val Loss: 0.5134 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[30/200] Train Loss: 0.5114 / Val Loss: 0.5126 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[31/200] Train Loss: 0.5091 / Val Loss: 0.5121 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[32/200] Train Loss: 0.5069 / Val Loss: 0.5116 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[33/200] Train Loss: 0.5049 / Val Loss: 0.5112 / Val Acc: 0.8044 / Change Acc: 0.2000\n",
            "[34/200] Train Loss: 0.5030 / Val Loss: 0.5109 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[35/200] Train Loss: 0.5011 / Val Loss: 0.5106 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[36/200] Train Loss: 0.4993 / Val Loss: 0.5103 / Val Acc: 0.8044 / Change Acc: 0.2182\n",
            "[37/200] Train Loss: 0.4976 / Val Loss: 0.5100 / Val Acc: 0.8010 / Change Acc: 0.2000\n",
            "[38/200] Train Loss: 0.4959 / Val Loss: 0.5097 / Val Acc: 0.7993 / Change Acc: 0.2000\n",
            "[39/200] Train Loss: 0.4942 / Val Loss: 0.5094 / Val Acc: 0.7976 / Change Acc: 0.2000\n",
            "[40/200] Train Loss: 0.4926 / Val Loss: 0.5091 / Val Acc: 0.7976 / Change Acc: 0.2000\n",
            "[41/200] Train Loss: 0.4909 / Val Loss: 0.5087 / Val Acc: 0.7942 / Change Acc: 0.2000\n",
            "[42/200] Train Loss: 0.4893 / Val Loss: 0.5084 / Val Acc: 0.7959 / Change Acc: 0.2000\n",
            "[43/200] Train Loss: 0.4878 / Val Loss: 0.5080 / Val Acc: 0.7976 / Change Acc: 0.2000\n",
            "[44/200] Train Loss: 0.4862 / Val Loss: 0.5076 / Val Acc: 0.7959 / Change Acc: 0.1818\n",
            "[45/200] Train Loss: 0.4847 / Val Loss: 0.5071 / Val Acc: 0.7959 / Change Acc: 0.1818\n",
            "[46/200] Train Loss: 0.4831 / Val Loss: 0.5067 / Val Acc: 0.7976 / Change Acc: 0.1818\n",
            "[47/200] Train Loss: 0.4816 / Val Loss: 0.5062 / Val Acc: 0.7976 / Change Acc: 0.1818\n",
            "[48/200] Train Loss: 0.4801 / Val Loss: 0.5057 / Val Acc: 0.8010 / Change Acc: 0.1818\n",
            "[49/200] Train Loss: 0.4787 / Val Loss: 0.5052 / Val Acc: 0.8027 / Change Acc: 0.1818\n",
            "[50/200] Train Loss: 0.4772 / Val Loss: 0.5047 / Val Acc: 0.8044 / Change Acc: 0.2000\n",
            "[51/200] Train Loss: 0.4758 / Val Loss: 0.5042 / Val Acc: 0.8027 / Change Acc: 0.1818\n",
            "[52/200] Train Loss: 0.4744 / Val Loss: 0.5036 / Val Acc: 0.8027 / Change Acc: 0.1818\n",
            "[53/200] Train Loss: 0.4730 / Val Loss: 0.5030 / Val Acc: 0.8044 / Change Acc: 0.1818\n",
            "[54/200] Train Loss: 0.4716 / Val Loss: 0.5024 / Val Acc: 0.8044 / Change Acc: 0.1818\n",
            "[55/200] Train Loss: 0.4703 / Val Loss: 0.5018 / Val Acc: 0.8044 / Change Acc: 0.1818\n",
            "[56/200] Train Loss: 0.4690 / Val Loss: 0.5012 / Val Acc: 0.8044 / Change Acc: 0.1818\n",
            "[57/200] Train Loss: 0.4677 / Val Loss: 0.5006 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[58/200] Train Loss: 0.4665 / Val Loss: 0.5000 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[59/200] Train Loss: 0.4652 / Val Loss: 0.4994 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[60/200] Train Loss: 0.4640 / Val Loss: 0.4987 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[61/200] Train Loss: 0.4629 / Val Loss: 0.4981 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[62/200] Train Loss: 0.4617 / Val Loss: 0.4975 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[63/200] Train Loss: 0.4606 / Val Loss: 0.4968 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[64/200] Train Loss: 0.4595 / Val Loss: 0.4962 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[65/200] Train Loss: 0.4585 / Val Loss: 0.4955 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[66/200] Train Loss: 0.4574 / Val Loss: 0.4949 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "[67/200] Train Loss: 0.4564 / Val Loss: 0.4943 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "[68/200] Train Loss: 0.4555 / Val Loss: 0.4936 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[69/200] Train Loss: 0.4545 / Val Loss: 0.4930 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[70/200] Train Loss: 0.4536 / Val Loss: 0.4924 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[71/200] Train Loss: 0.4527 / Val Loss: 0.4918 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[72/200] Train Loss: 0.4519 / Val Loss: 0.4912 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[73/200] Train Loss: 0.4510 / Val Loss: 0.4906 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[74/200] Train Loss: 0.4502 / Val Loss: 0.4900 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[75/200] Train Loss: 0.4494 / Val Loss: 0.4894 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[76/200] Train Loss: 0.4486 / Val Loss: 0.4888 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[77/200] Train Loss: 0.4479 / Val Loss: 0.4882 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[78/200] Train Loss: 0.4472 / Val Loss: 0.4877 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[79/200] Train Loss: 0.4465 / Val Loss: 0.4871 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[80/200] Train Loss: 0.4458 / Val Loss: 0.4866 / Val Acc: 0.8248 / Change Acc: 0.1818\n",
            "[81/200] Train Loss: 0.4451 / Val Loss: 0.4860 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[82/200] Train Loss: 0.4445 / Val Loss: 0.4855 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[83/200] Train Loss: 0.4438 / Val Loss: 0.4850 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[84/200] Train Loss: 0.4432 / Val Loss: 0.4844 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[85/200] Train Loss: 0.4426 / Val Loss: 0.4839 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[86/200] Train Loss: 0.4421 / Val Loss: 0.4834 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[87/200] Train Loss: 0.4415 / Val Loss: 0.4829 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[88/200] Train Loss: 0.4410 / Val Loss: 0.4824 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[89/200] Train Loss: 0.4404 / Val Loss: 0.4819 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[90/200] Train Loss: 0.4399 / Val Loss: 0.4815 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[91/200] Train Loss: 0.4394 / Val Loss: 0.4810 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[92/200] Train Loss: 0.4389 / Val Loss: 0.4805 / Val Acc: 0.8231 / Change Acc: 0.2182\n",
            "[93/200] Train Loss: 0.4385 / Val Loss: 0.4800 / Val Acc: 0.8231 / Change Acc: 0.2182\n",
            "[94/200] Train Loss: 0.4380 / Val Loss: 0.4796 / Val Acc: 0.8231 / Change Acc: 0.2182\n",
            "[95/200] Train Loss: 0.4375 / Val Loss: 0.4791 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[96/200] Train Loss: 0.4371 / Val Loss: 0.4787 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[97/200] Train Loss: 0.4367 / Val Loss: 0.4783 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[98/200] Train Loss: 0.4362 / Val Loss: 0.4778 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[99/200] Train Loss: 0.4358 / Val Loss: 0.4774 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[100/200] Train Loss: 0.4354 / Val Loss: 0.4770 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[101/200] Train Loss: 0.4350 / Val Loss: 0.4766 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[102/200] Train Loss: 0.4346 / Val Loss: 0.4762 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[103/200] Train Loss: 0.4343 / Val Loss: 0.4758 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[104/200] Train Loss: 0.4339 / Val Loss: 0.4754 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[105/200] Train Loss: 0.4335 / Val Loss: 0.4750 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[106/200] Train Loss: 0.4332 / Val Loss: 0.4746 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[107/200] Train Loss: 0.4328 / Val Loss: 0.4742 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[108/200] Train Loss: 0.4325 / Val Loss: 0.4738 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[109/200] Train Loss: 0.4322 / Val Loss: 0.4735 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[110/200] Train Loss: 0.4318 / Val Loss: 0.4731 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[111/200] Train Loss: 0.4315 / Val Loss: 0.4728 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[112/200] Train Loss: 0.4312 / Val Loss: 0.4724 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[113/200] Train Loss: 0.4309 / Val Loss: 0.4721 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[114/200] Train Loss: 0.4306 / Val Loss: 0.4717 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[115/200] Train Loss: 0.4303 / Val Loss: 0.4714 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[116/200] Train Loss: 0.4300 / Val Loss: 0.4710 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[117/200] Train Loss: 0.4297 / Val Loss: 0.4707 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[118/200] Train Loss: 0.4294 / Val Loss: 0.4704 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[119/200] Train Loss: 0.4291 / Val Loss: 0.4701 / Val Acc: 0.8231 / Change Acc: 0.1818\n",
            "[120/200] Train Loss: 0.4289 / Val Loss: 0.4697 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[121/200] Train Loss: 0.4286 / Val Loss: 0.4694 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[122/200] Train Loss: 0.4283 / Val Loss: 0.4691 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[123/200] Train Loss: 0.4281 / Val Loss: 0.4688 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[124/200] Train Loss: 0.4278 / Val Loss: 0.4685 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[125/200] Train Loss: 0.4276 / Val Loss: 0.4682 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[126/200] Train Loss: 0.4273 / Val Loss: 0.4679 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[127/200] Train Loss: 0.4271 / Val Loss: 0.4677 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[128/200] Train Loss: 0.4269 / Val Loss: 0.4674 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[129/200] Train Loss: 0.4266 / Val Loss: 0.4671 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[130/200] Train Loss: 0.4264 / Val Loss: 0.4668 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[131/200] Train Loss: 0.4262 / Val Loss: 0.4666 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[132/200] Train Loss: 0.4259 / Val Loss: 0.4663 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[133/200] Train Loss: 0.4257 / Val Loss: 0.4660 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[134/200] Train Loss: 0.4255 / Val Loss: 0.4658 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[135/200] Train Loss: 0.4253 / Val Loss: 0.4655 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[136/200] Train Loss: 0.4251 / Val Loss: 0.4653 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[137/200] Train Loss: 0.4249 / Val Loss: 0.4650 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[138/200] Train Loss: 0.4247 / Val Loss: 0.4648 / Val Acc: 0.8146 / Change Acc: 0.2000\n",
            "[139/200] Train Loss: 0.4245 / Val Loss: 0.4645 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[140/200] Train Loss: 0.4243 / Val Loss: 0.4643 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[141/200] Train Loss: 0.4241 / Val Loss: 0.4641 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[142/200] Train Loss: 0.4239 / Val Loss: 0.4638 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[143/200] Train Loss: 0.4237 / Val Loss: 0.4636 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[144/200] Train Loss: 0.4235 / Val Loss: 0.4634 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[145/200] Train Loss: 0.4233 / Val Loss: 0.4632 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[146/200] Train Loss: 0.4231 / Val Loss: 0.4630 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[147/200] Train Loss: 0.4229 / Val Loss: 0.4627 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[148/200] Train Loss: 0.4228 / Val Loss: 0.4625 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[149/200] Train Loss: 0.4226 / Val Loss: 0.4623 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[150/200] Train Loss: 0.4224 / Val Loss: 0.4621 / Val Acc: 0.8112 / Change Acc: 0.2000\n",
            "[151/200] Train Loss: 0.4223 / Val Loss: 0.4619 / Val Acc: 0.8112 / Change Acc: 0.2000\n",
            "[152/200] Train Loss: 0.4221 / Val Loss: 0.4618 / Val Acc: 0.8112 / Change Acc: 0.2000\n",
            "[153/200] Train Loss: 0.4219 / Val Loss: 0.4616 / Val Acc: 0.8112 / Change Acc: 0.2000\n",
            "[154/200] Train Loss: 0.4218 / Val Loss: 0.4614 / Val Acc: 0.8112 / Change Acc: 0.2000\n",
            "[155/200] Train Loss: 0.4216 / Val Loss: 0.4612 / Val Acc: 0.8095 / Change Acc: 0.2000\n",
            "[156/200] Train Loss: 0.4214 / Val Loss: 0.4610 / Val Acc: 0.8095 / Change Acc: 0.2000\n",
            "[157/200] Train Loss: 0.4213 / Val Loss: 0.4608 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[158/200] Train Loss: 0.4211 / Val Loss: 0.4606 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[159/200] Train Loss: 0.4210 / Val Loss: 0.4605 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[160/200] Train Loss: 0.4208 / Val Loss: 0.4603 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[161/200] Train Loss: 0.4207 / Val Loss: 0.4601 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[162/200] Train Loss: 0.4205 / Val Loss: 0.4599 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[163/200] Train Loss: 0.4204 / Val Loss: 0.4598 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[164/200] Train Loss: 0.4203 / Val Loss: 0.4596 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[165/200] Train Loss: 0.4201 / Val Loss: 0.4595 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[166/200] Train Loss: 0.4200 / Val Loss: 0.4593 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[167/200] Train Loss: 0.4198 / Val Loss: 0.4592 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[168/200] Train Loss: 0.4197 / Val Loss: 0.4590 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[169/200] Train Loss: 0.4196 / Val Loss: 0.4589 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[170/200] Train Loss: 0.4194 / Val Loss: 0.4587 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[171/200] Train Loss: 0.4193 / Val Loss: 0.4586 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[172/200] Train Loss: 0.4192 / Val Loss: 0.4584 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[173/200] Train Loss: 0.4190 / Val Loss: 0.4583 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[174/200] Train Loss: 0.4189 / Val Loss: 0.4581 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[175/200] Train Loss: 0.4188 / Val Loss: 0.4580 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[176/200] Train Loss: 0.4187 / Val Loss: 0.4579 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[177/200] Train Loss: 0.4186 / Val Loss: 0.4577 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[178/200] Train Loss: 0.4184 / Val Loss: 0.4576 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[179/200] Train Loss: 0.4183 / Val Loss: 0.4575 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[180/200] Train Loss: 0.4182 / Val Loss: 0.4573 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[181/200] Train Loss: 0.4181 / Val Loss: 0.4572 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[182/200] Train Loss: 0.4180 / Val Loss: 0.4571 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[183/200] Train Loss: 0.4179 / Val Loss: 0.4569 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[184/200] Train Loss: 0.4177 / Val Loss: 0.4568 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[185/200] Train Loss: 0.4176 / Val Loss: 0.4567 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[186/200] Train Loss: 0.4175 / Val Loss: 0.4566 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[187/200] Train Loss: 0.4174 / Val Loss: 0.4565 / Val Acc: 0.8061 / Change Acc: 0.2000\n",
            "[188/200] Train Loss: 0.4173 / Val Loss: 0.4563 / Val Acc: 0.8044 / Change Acc: 0.2000\n",
            "[189/200] Train Loss: 0.4172 / Val Loss: 0.4562 / Val Acc: 0.8044 / Change Acc: 0.2000\n",
            "[190/200] Train Loss: 0.4171 / Val Loss: 0.4561 / Val Acc: 0.8044 / Change Acc: 0.2000\n",
            "[191/200] Train Loss: 0.4170 / Val Loss: 0.4560 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[192/200] Train Loss: 0.4169 / Val Loss: 0.4559 / Val Acc: 0.8010 / Change Acc: 0.2000\n",
            "[193/200] Train Loss: 0.4168 / Val Loss: 0.4558 / Val Acc: 0.8010 / Change Acc: 0.2000\n",
            "[194/200] Train Loss: 0.4167 / Val Loss: 0.4557 / Val Acc: 0.8010 / Change Acc: 0.2000\n",
            "[195/200] Train Loss: 0.4166 / Val Loss: 0.4556 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[196/200] Train Loss: 0.4165 / Val Loss: 0.4554 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[197/200] Train Loss: 0.4164 / Val Loss: 0.4553 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[198/200] Train Loss: 0.4163 / Val Loss: 0.4552 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[199/200] Train Loss: 0.4162 / Val Loss: 0.4551 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "[200/200] Train Loss: 0.4161 / Val Loss: 0.4550 / Val Acc: 0.8027 / Change Acc: 0.2000\n",
            "Test Result: test_loss=0.5020 / test_acc=0.6913 / test_change_acc=0.4062\n",
            "Training with lr=0.0001, hidden_dim=64, strict_mode=False\n",
            "[1/200] Train Loss: 0.7113 / Val Loss: 0.7125 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.7045 / Val Loss: 0.7044 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[3/200] Train Loss: 0.6980 / Val Loss: 0.6962 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[4/200] Train Loss: 0.6912 / Val Loss: 0.6873 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[5/200] Train Loss: 0.6835 / Val Loss: 0.6771 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[6/200] Train Loss: 0.6746 / Val Loss: 0.6652 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[7/200] Train Loss: 0.6640 / Val Loss: 0.6512 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[8/200] Train Loss: 0.6512 / Val Loss: 0.6346 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[9/200] Train Loss: 0.6359 / Val Loss: 0.6156 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[10/200] Train Loss: 0.6179 / Val Loss: 0.5947 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[11/200] Train Loss: 0.5975 / Val Loss: 0.5732 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[12/200] Train Loss: 0.5764 / Val Loss: 0.5535 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[13/200] Train Loss: 0.5574 / Val Loss: 0.5380 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[14/200] Train Loss: 0.5428 / Val Loss: 0.5277 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[15/200] Train Loss: 0.5325 / Val Loss: 0.5213 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[16/200] Train Loss: 0.5255 / Val Loss: 0.5175 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[17/200] Train Loss: 0.5203 / Val Loss: 0.5153 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[18/200] Train Loss: 0.5161 / Val Loss: 0.5140 / Val Acc: 0.7024 / Change Acc: 0.3273\n",
            "[19/200] Train Loss: 0.5126 / Val Loss: 0.5131 / Val Acc: 0.7007 / Change Acc: 0.3091\n",
            "[20/200] Train Loss: 0.5093 / Val Loss: 0.5125 / Val Acc: 0.7041 / Change Acc: 0.3091\n",
            "[21/200] Train Loss: 0.5063 / Val Loss: 0.5121 / Val Acc: 0.7007 / Change Acc: 0.2727\n",
            "[22/200] Train Loss: 0.5033 / Val Loss: 0.5117 / Val Acc: 0.7024 / Change Acc: 0.2727\n",
            "[23/200] Train Loss: 0.5003 / Val Loss: 0.5113 / Val Acc: 0.7024 / Change Acc: 0.2545\n",
            "[24/200] Train Loss: 0.4973 / Val Loss: 0.5109 / Val Acc: 0.7024 / Change Acc: 0.2545\n",
            "[25/200] Train Loss: 0.4943 / Val Loss: 0.5104 / Val Acc: 0.7024 / Change Acc: 0.2545\n",
            "[26/200] Train Loss: 0.4912 / Val Loss: 0.5099 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[27/200] Train Loss: 0.4880 / Val Loss: 0.5092 / Val Acc: 0.7075 / Change Acc: 0.2727\n",
            "[28/200] Train Loss: 0.4848 / Val Loss: 0.5084 / Val Acc: 0.7075 / Change Acc: 0.2727\n",
            "[29/200] Train Loss: 0.4815 / Val Loss: 0.5075 / Val Acc: 0.7075 / Change Acc: 0.2727\n",
            "[30/200] Train Loss: 0.4782 / Val Loss: 0.5065 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[31/200] Train Loss: 0.4749 / Val Loss: 0.5053 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[32/200] Train Loss: 0.4717 / Val Loss: 0.5040 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[33/200] Train Loss: 0.4685 / Val Loss: 0.5025 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[34/200] Train Loss: 0.4655 / Val Loss: 0.5010 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[35/200] Train Loss: 0.4626 / Val Loss: 0.4995 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[36/200] Train Loss: 0.4599 / Val Loss: 0.4979 / Val Acc: 0.7058 / Change Acc: 0.2727\n",
            "[37/200] Train Loss: 0.4573 / Val Loss: 0.4964 / Val Acc: 0.7075 / Change Acc: 0.2727\n",
            "[38/200] Train Loss: 0.4550 / Val Loss: 0.4949 / Val Acc: 0.7058 / Change Acc: 0.2545\n",
            "[39/200] Train Loss: 0.4528 / Val Loss: 0.4934 / Val Acc: 0.7058 / Change Acc: 0.2545\n",
            "[40/200] Train Loss: 0.4509 / Val Loss: 0.4920 / Val Acc: 0.7058 / Change Acc: 0.2545\n",
            "[41/200] Train Loss: 0.4491 / Val Loss: 0.4908 / Val Acc: 0.7058 / Change Acc: 0.2545\n",
            "[42/200] Train Loss: 0.4474 / Val Loss: 0.4895 / Val Acc: 0.7041 / Change Acc: 0.2364\n",
            "[43/200] Train Loss: 0.4459 / Val Loss: 0.4884 / Val Acc: 0.7058 / Change Acc: 0.2364\n",
            "[44/200] Train Loss: 0.4445 / Val Loss: 0.4873 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[45/200] Train Loss: 0.4432 / Val Loss: 0.4863 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[46/200] Train Loss: 0.4420 / Val Loss: 0.4853 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[47/200] Train Loss: 0.4409 / Val Loss: 0.4844 / Val Acc: 0.7092 / Change Acc: 0.2364\n",
            "[48/200] Train Loss: 0.4399 / Val Loss: 0.4835 / Val Acc: 0.7109 / Change Acc: 0.2364\n",
            "[49/200] Train Loss: 0.4390 / Val Loss: 0.4827 / Val Acc: 0.7092 / Change Acc: 0.2182\n",
            "[50/200] Train Loss: 0.4381 / Val Loss: 0.4819 / Val Acc: 0.7092 / Change Acc: 0.2182\n",
            "[51/200] Train Loss: 0.4373 / Val Loss: 0.4812 / Val Acc: 0.7126 / Change Acc: 0.2182\n",
            "[52/200] Train Loss: 0.4365 / Val Loss: 0.4805 / Val Acc: 0.7126 / Change Acc: 0.2182\n",
            "[53/200] Train Loss: 0.4358 / Val Loss: 0.4798 / Val Acc: 0.7143 / Change Acc: 0.2182\n",
            "[54/200] Train Loss: 0.4351 / Val Loss: 0.4792 / Val Acc: 0.7160 / Change Acc: 0.2182\n",
            "[55/200] Train Loss: 0.4344 / Val Loss: 0.4785 / Val Acc: 0.7160 / Change Acc: 0.2182\n",
            "[56/200] Train Loss: 0.4338 / Val Loss: 0.4779 / Val Acc: 0.7160 / Change Acc: 0.2182\n",
            "[57/200] Train Loss: 0.4332 / Val Loss: 0.4774 / Val Acc: 0.7177 / Change Acc: 0.2182\n",
            "[58/200] Train Loss: 0.4327 / Val Loss: 0.4768 / Val Acc: 0.7177 / Change Acc: 0.2182\n",
            "[59/200] Train Loss: 0.4321 / Val Loss: 0.4763 / Val Acc: 0.7194 / Change Acc: 0.2182\n",
            "[60/200] Train Loss: 0.4316 / Val Loss: 0.4758 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[61/200] Train Loss: 0.4311 / Val Loss: 0.4753 / Val Acc: 0.7211 / Change Acc: 0.2182\n",
            "[62/200] Train Loss: 0.4306 / Val Loss: 0.4748 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[63/200] Train Loss: 0.4302 / Val Loss: 0.4743 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[64/200] Train Loss: 0.4297 / Val Loss: 0.4738 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[65/200] Train Loss: 0.4293 / Val Loss: 0.4734 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[66/200] Train Loss: 0.4289 / Val Loss: 0.4729 / Val Acc: 0.7228 / Change Acc: 0.2182\n",
            "[67/200] Train Loss: 0.4285 / Val Loss: 0.4725 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[68/200] Train Loss: 0.4281 / Val Loss: 0.4721 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[69/200] Train Loss: 0.4277 / Val Loss: 0.4717 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[70/200] Train Loss: 0.4274 / Val Loss: 0.4713 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[71/200] Train Loss: 0.4270 / Val Loss: 0.4709 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[72/200] Train Loss: 0.4267 / Val Loss: 0.4705 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[73/200] Train Loss: 0.4264 / Val Loss: 0.4702 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[74/200] Train Loss: 0.4260 / Val Loss: 0.4698 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[75/200] Train Loss: 0.4257 / Val Loss: 0.4694 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[76/200] Train Loss: 0.4254 / Val Loss: 0.4691 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[77/200] Train Loss: 0.4251 / Val Loss: 0.4687 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[78/200] Train Loss: 0.4248 / Val Loss: 0.4684 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[79/200] Train Loss: 0.4245 / Val Loss: 0.4680 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[80/200] Train Loss: 0.4242 / Val Loss: 0.4677 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[81/200] Train Loss: 0.4239 / Val Loss: 0.4674 / Val Acc: 0.7245 / Change Acc: 0.2182\n",
            "[82/200] Train Loss: 0.4237 / Val Loss: 0.4671 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[83/200] Train Loss: 0.4234 / Val Loss: 0.4668 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[84/200] Train Loss: 0.4231 / Val Loss: 0.4665 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[85/200] Train Loss: 0.4229 / Val Loss: 0.4662 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[86/200] Train Loss: 0.4226 / Val Loss: 0.4659 / Val Acc: 0.7262 / Change Acc: 0.2182\n",
            "[87/200] Train Loss: 0.4224 / Val Loss: 0.4656 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[88/200] Train Loss: 0.4222 / Val Loss: 0.4653 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[89/200] Train Loss: 0.4219 / Val Loss: 0.4650 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[90/200] Train Loss: 0.4217 / Val Loss: 0.4647 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[91/200] Train Loss: 0.4215 / Val Loss: 0.4645 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[92/200] Train Loss: 0.4212 / Val Loss: 0.4642 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[93/200] Train Loss: 0.4210 / Val Loss: 0.4639 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[94/200] Train Loss: 0.4208 / Val Loss: 0.4637 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[95/200] Train Loss: 0.4206 / Val Loss: 0.4634 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[96/200] Train Loss: 0.4204 / Val Loss: 0.4632 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[97/200] Train Loss: 0.4202 / Val Loss: 0.4629 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[98/200] Train Loss: 0.4200 / Val Loss: 0.4627 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[99/200] Train Loss: 0.4198 / Val Loss: 0.4625 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[100/200] Train Loss: 0.4196 / Val Loss: 0.4622 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[101/200] Train Loss: 0.4194 / Val Loss: 0.4620 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[102/200] Train Loss: 0.4192 / Val Loss: 0.4618 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[103/200] Train Loss: 0.4190 / Val Loss: 0.4616 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[104/200] Train Loss: 0.4188 / Val Loss: 0.4613 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[105/200] Train Loss: 0.4187 / Val Loss: 0.4611 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[106/200] Train Loss: 0.4185 / Val Loss: 0.4609 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[107/200] Train Loss: 0.4183 / Val Loss: 0.4607 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[108/200] Train Loss: 0.4181 / Val Loss: 0.4605 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[109/200] Train Loss: 0.4180 / Val Loss: 0.4603 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[110/200] Train Loss: 0.4178 / Val Loss: 0.4601 / Val Acc: 0.7296 / Change Acc: 0.2000\n",
            "[111/200] Train Loss: 0.4176 / Val Loss: 0.4599 / Val Acc: 0.7296 / Change Acc: 0.2000\n",
            "[112/200] Train Loss: 0.4175 / Val Loss: 0.4598 / Val Acc: 0.7313 / Change Acc: 0.2000\n",
            "[113/200] Train Loss: 0.4173 / Val Loss: 0.4596 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[114/200] Train Loss: 0.4172 / Val Loss: 0.4594 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[115/200] Train Loss: 0.4170 / Val Loss: 0.4592 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[116/200] Train Loss: 0.4169 / Val Loss: 0.4591 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[117/200] Train Loss: 0.4167 / Val Loss: 0.4589 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[118/200] Train Loss: 0.4166 / Val Loss: 0.4587 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[119/200] Train Loss: 0.4164 / Val Loss: 0.4586 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[120/200] Train Loss: 0.4163 / Val Loss: 0.4584 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[121/200] Train Loss: 0.4161 / Val Loss: 0.4583 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[122/200] Train Loss: 0.4160 / Val Loss: 0.4581 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[123/200] Train Loss: 0.4158 / Val Loss: 0.4580 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[124/200] Train Loss: 0.4157 / Val Loss: 0.4578 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[125/200] Train Loss: 0.4156 / Val Loss: 0.4577 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[126/200] Train Loss: 0.4154 / Val Loss: 0.4576 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[127/200] Train Loss: 0.4153 / Val Loss: 0.4574 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[128/200] Train Loss: 0.4152 / Val Loss: 0.4573 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[129/200] Train Loss: 0.4150 / Val Loss: 0.4572 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[130/200] Train Loss: 0.4149 / Val Loss: 0.4570 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[131/200] Train Loss: 0.4148 / Val Loss: 0.4569 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[132/200] Train Loss: 0.4147 / Val Loss: 0.4568 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[133/200] Train Loss: 0.4145 / Val Loss: 0.4567 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[134/200] Train Loss: 0.4144 / Val Loss: 0.4566 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[135/200] Train Loss: 0.4143 / Val Loss: 0.4565 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[136/200] Train Loss: 0.4142 / Val Loss: 0.4564 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[137/200] Train Loss: 0.4141 / Val Loss: 0.4562 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[138/200] Train Loss: 0.4139 / Val Loss: 0.4561 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[139/200] Train Loss: 0.4138 / Val Loss: 0.4560 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[140/200] Train Loss: 0.4137 / Val Loss: 0.4559 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[141/200] Train Loss: 0.4136 / Val Loss: 0.4559 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[142/200] Train Loss: 0.4135 / Val Loss: 0.4558 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[143/200] Train Loss: 0.4134 / Val Loss: 0.4557 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[144/200] Train Loss: 0.4132 / Val Loss: 0.4556 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[145/200] Train Loss: 0.4131 / Val Loss: 0.4555 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[146/200] Train Loss: 0.4130 / Val Loss: 0.4554 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[147/200] Train Loss: 0.4129 / Val Loss: 0.4553 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[148/200] Train Loss: 0.4128 / Val Loss: 0.4553 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[149/200] Train Loss: 0.4127 / Val Loss: 0.4552 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[150/200] Train Loss: 0.4126 / Val Loss: 0.4551 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[151/200] Train Loss: 0.4125 / Val Loss: 0.4550 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[152/200] Train Loss: 0.4124 / Val Loss: 0.4550 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[153/200] Train Loss: 0.4123 / Val Loss: 0.4549 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[154/200] Train Loss: 0.4122 / Val Loss: 0.4549 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[155/200] Train Loss: 0.4121 / Val Loss: 0.4548 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[156/200] Train Loss: 0.4119 / Val Loss: 0.4547 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[157/200] Train Loss: 0.4118 / Val Loss: 0.4547 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[158/200] Train Loss: 0.4117 / Val Loss: 0.4546 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[159/200] Train Loss: 0.4116 / Val Loss: 0.4546 / Val Acc: 0.7381 / Change Acc: 0.1818\n",
            "[160/200] Train Loss: 0.4115 / Val Loss: 0.4545 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[161/200] Train Loss: 0.4114 / Val Loss: 0.4545 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[162/200] Train Loss: 0.4113 / Val Loss: 0.4544 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[163/200] Train Loss: 0.4112 / Val Loss: 0.4544 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[164/200] Train Loss: 0.4111 / Val Loss: 0.4544 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[165/200] Train Loss: 0.4110 / Val Loss: 0.4543 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[166/200] Train Loss: 0.4109 / Val Loss: 0.4543 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[167/200] Train Loss: 0.4108 / Val Loss: 0.4543 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[168/200] Train Loss: 0.4107 / Val Loss: 0.4542 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[169/200] Train Loss: 0.4106 / Val Loss: 0.4542 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[170/200] Train Loss: 0.4105 / Val Loss: 0.4542 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[171/200] Train Loss: 0.4104 / Val Loss: 0.4541 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[172/200] Train Loss: 0.4103 / Val Loss: 0.4541 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[173/200] Train Loss: 0.4102 / Val Loss: 0.4541 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[174/200] Train Loss: 0.4101 / Val Loss: 0.4541 / Val Acc: 0.7398 / Change Acc: 0.1636\n",
            "[175/200] Train Loss: 0.4100 / Val Loss: 0.4541 / Val Acc: 0.7398 / Change Acc: 0.1636\n",
            "[176/200] Train Loss: 0.4099 / Val Loss: 0.4541 / Val Acc: 0.7415 / Change Acc: 0.1636\n",
            "[177/200] Train Loss: 0.4098 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[178/200] Train Loss: 0.4098 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[179/200] Train Loss: 0.4097 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[180/200] Train Loss: 0.4096 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[181/200] Train Loss: 0.4095 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[182/200] Train Loss: 0.4094 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[183/200] Train Loss: 0.4093 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[184/200] Train Loss: 0.4092 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[185/200] Train Loss: 0.4091 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[186/200] Train Loss: 0.4090 / Val Loss: 0.4540 / Val Acc: 0.7432 / Change Acc: 0.1636\n",
            "[187/200] Train Loss: 0.4089 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[188/200] Train Loss: 0.4088 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[189/200] Train Loss: 0.4087 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[190/200] Train Loss: 0.4086 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[191/200] Train Loss: 0.4085 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[192/200] Train Loss: 0.4084 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[193/200] Train Loss: 0.4083 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "[194/200] Train Loss: 0.4082 / Val Loss: 0.4540 / Val Acc: 0.7449 / Change Acc: 0.1636\n",
            "Early stopping at epoch 195\n",
            "Test Result: test_loss=0.5035 / test_acc=0.7628 / test_change_acc=0.5625\n",
            "Training with lr=0.0001, hidden_dim=64, strict_mode=True\n",
            "[1/200] Train Loss: 0.7043 / Val Loss: 0.7044 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.6979 / Val Loss: 0.6968 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[3/200] Train Loss: 0.6917 / Val Loss: 0.6889 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[4/200] Train Loss: 0.6849 / Val Loss: 0.6801 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[5/200] Train Loss: 0.6770 / Val Loss: 0.6697 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[6/200] Train Loss: 0.6674 / Val Loss: 0.6571 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[7/200] Train Loss: 0.6557 / Val Loss: 0.6420 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[8/200] Train Loss: 0.6413 / Val Loss: 0.6240 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[9/200] Train Loss: 0.6238 / Val Loss: 0.6036 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[10/200] Train Loss: 0.6036 / Val Loss: 0.5821 / Val Acc: 0.3520 / Change Acc: 0.6182\n",
            "[11/200] Train Loss: 0.5818 / Val Loss: 0.5619 / Val Acc: 0.6463 / Change Acc: 0.4545\n",
            "[12/200] Train Loss: 0.5613 / Val Loss: 0.5456 / Val Acc: 0.7398 / Change Acc: 0.3636\n",
            "[13/200] Train Loss: 0.5451 / Val Loss: 0.5345 / Val Acc: 0.7959 / Change Acc: 0.2727\n",
            "[14/200] Train Loss: 0.5337 / Val Loss: 0.5276 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[15/200] Train Loss: 0.5261 / Val Loss: 0.5234 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[16/200] Train Loss: 0.5207 / Val Loss: 0.5210 / Val Acc: 0.8095 / Change Acc: 0.1818\n",
            "[17/200] Train Loss: 0.5166 / Val Loss: 0.5196 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[18/200] Train Loss: 0.5132 / Val Loss: 0.5188 / Val Acc: 0.8112 / Change Acc: 0.1636\n",
            "[19/200] Train Loss: 0.5101 / Val Loss: 0.5182 / Val Acc: 0.8112 / Change Acc: 0.1818\n",
            "[20/200] Train Loss: 0.5073 / Val Loss: 0.5177 / Val Acc: 0.8129 / Change Acc: 0.2000\n",
            "[21/200] Train Loss: 0.5045 / Val Loss: 0.5174 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[22/200] Train Loss: 0.5017 / Val Loss: 0.5170 / Val Acc: 0.8146 / Change Acc: 0.2182\n",
            "[23/200] Train Loss: 0.4989 / Val Loss: 0.5165 / Val Acc: 0.8146 / Change Acc: 0.2182\n",
            "[24/200] Train Loss: 0.4960 / Val Loss: 0.5161 / Val Acc: 0.8095 / Change Acc: 0.2000\n",
            "[25/200] Train Loss: 0.4931 / Val Loss: 0.5155 / Val Acc: 0.8095 / Change Acc: 0.2000\n",
            "[26/200] Train Loss: 0.4901 / Val Loss: 0.5149 / Val Acc: 0.8112 / Change Acc: 0.2000\n",
            "[27/200] Train Loss: 0.4871 / Val Loss: 0.5142 / Val Acc: 0.8095 / Change Acc: 0.2000\n",
            "[28/200] Train Loss: 0.4839 / Val Loss: 0.5133 / Val Acc: 0.8078 / Change Acc: 0.2000\n",
            "[29/200] Train Loss: 0.4807 / Val Loss: 0.5124 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[30/200] Train Loss: 0.4775 / Val Loss: 0.5113 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[31/200] Train Loss: 0.4743 / Val Loss: 0.5101 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[32/200] Train Loss: 0.4711 / Val Loss: 0.5089 / Val Acc: 0.8095 / Change Acc: 0.1818\n",
            "[33/200] Train Loss: 0.4680 / Val Loss: 0.5075 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[34/200] Train Loss: 0.4650 / Val Loss: 0.5060 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[35/200] Train Loss: 0.4621 / Val Loss: 0.5045 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[36/200] Train Loss: 0.4594 / Val Loss: 0.5030 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[37/200] Train Loss: 0.4569 / Val Loss: 0.5015 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[38/200] Train Loss: 0.4545 / Val Loss: 0.5000 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[39/200] Train Loss: 0.4524 / Val Loss: 0.4986 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[40/200] Train Loss: 0.4504 / Val Loss: 0.4973 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[41/200] Train Loss: 0.4486 / Val Loss: 0.4960 / Val Acc: 0.8214 / Change Acc: 0.2182\n",
            "[42/200] Train Loss: 0.4469 / Val Loss: 0.4947 / Val Acc: 0.8214 / Change Acc: 0.2182\n",
            "[43/200] Train Loss: 0.4453 / Val Loss: 0.4936 / Val Acc: 0.8248 / Change Acc: 0.2364\n",
            "[44/200] Train Loss: 0.4439 / Val Loss: 0.4925 / Val Acc: 0.8248 / Change Acc: 0.2364\n",
            "[45/200] Train Loss: 0.4426 / Val Loss: 0.4914 / Val Acc: 0.8248 / Change Acc: 0.2364\n",
            "[46/200] Train Loss: 0.4415 / Val Loss: 0.4904 / Val Acc: 0.8248 / Change Acc: 0.2364\n",
            "[47/200] Train Loss: 0.4404 / Val Loss: 0.4895 / Val Acc: 0.8248 / Change Acc: 0.2364\n",
            "[48/200] Train Loss: 0.4393 / Val Loss: 0.4886 / Val Acc: 0.8265 / Change Acc: 0.2364\n",
            "[49/200] Train Loss: 0.4384 / Val Loss: 0.4877 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[50/200] Train Loss: 0.4375 / Val Loss: 0.4869 / Val Acc: 0.8282 / Change Acc: 0.2182\n",
            "[51/200] Train Loss: 0.4367 / Val Loss: 0.4861 / Val Acc: 0.8333 / Change Acc: 0.2364\n",
            "[52/200] Train Loss: 0.4359 / Val Loss: 0.4854 / Val Acc: 0.8333 / Change Acc: 0.2182\n",
            "[53/200] Train Loss: 0.4352 / Val Loss: 0.4847 / Val Acc: 0.8350 / Change Acc: 0.2182\n",
            "[54/200] Train Loss: 0.4345 / Val Loss: 0.4840 / Val Acc: 0.8350 / Change Acc: 0.2182\n",
            "[55/200] Train Loss: 0.4338 / Val Loss: 0.4833 / Val Acc: 0.8333 / Change Acc: 0.2182\n",
            "[56/200] Train Loss: 0.4332 / Val Loss: 0.4827 / Val Acc: 0.8316 / Change Acc: 0.2182\n",
            "[57/200] Train Loss: 0.4326 / Val Loss: 0.4821 / Val Acc: 0.8316 / Change Acc: 0.2182\n",
            "[58/200] Train Loss: 0.4320 / Val Loss: 0.4815 / Val Acc: 0.8316 / Change Acc: 0.2182\n",
            "[59/200] Train Loss: 0.4315 / Val Loss: 0.4809 / Val Acc: 0.8316 / Change Acc: 0.2182\n",
            "[60/200] Train Loss: 0.4310 / Val Loss: 0.4804 / Val Acc: 0.8282 / Change Acc: 0.2000\n",
            "[61/200] Train Loss: 0.4305 / Val Loss: 0.4799 / Val Acc: 0.8282 / Change Acc: 0.2000\n",
            "[62/200] Train Loss: 0.4300 / Val Loss: 0.4793 / Val Acc: 0.8282 / Change Acc: 0.2000\n",
            "[63/200] Train Loss: 0.4295 / Val Loss: 0.4788 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[64/200] Train Loss: 0.4291 / Val Loss: 0.4784 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[65/200] Train Loss: 0.4286 / Val Loss: 0.4779 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[66/200] Train Loss: 0.4282 / Val Loss: 0.4775 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[67/200] Train Loss: 0.4278 / Val Loss: 0.4770 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[68/200] Train Loss: 0.4274 / Val Loss: 0.4766 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[69/200] Train Loss: 0.4270 / Val Loss: 0.4762 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[70/200] Train Loss: 0.4267 / Val Loss: 0.4758 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[71/200] Train Loss: 0.4263 / Val Loss: 0.4754 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[72/200] Train Loss: 0.4259 / Val Loss: 0.4751 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[73/200] Train Loss: 0.4256 / Val Loss: 0.4747 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[74/200] Train Loss: 0.4253 / Val Loss: 0.4743 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[75/200] Train Loss: 0.4249 / Val Loss: 0.4740 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[76/200] Train Loss: 0.4246 / Val Loss: 0.4737 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[77/200] Train Loss: 0.4243 / Val Loss: 0.4733 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[78/200] Train Loss: 0.4240 / Val Loss: 0.4730 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[79/200] Train Loss: 0.4237 / Val Loss: 0.4727 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[80/200] Train Loss: 0.4234 / Val Loss: 0.4724 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[81/200] Train Loss: 0.4231 / Val Loss: 0.4721 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[82/200] Train Loss: 0.4228 / Val Loss: 0.4718 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[83/200] Train Loss: 0.4226 / Val Loss: 0.4715 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[84/200] Train Loss: 0.4223 / Val Loss: 0.4713 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[85/200] Train Loss: 0.4220 / Val Loss: 0.4710 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[86/200] Train Loss: 0.4218 / Val Loss: 0.4708 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[87/200] Train Loss: 0.4215 / Val Loss: 0.4705 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[88/200] Train Loss: 0.4213 / Val Loss: 0.4703 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[89/200] Train Loss: 0.4210 / Val Loss: 0.4700 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[90/200] Train Loss: 0.4208 / Val Loss: 0.4698 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[91/200] Train Loss: 0.4206 / Val Loss: 0.4696 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[92/200] Train Loss: 0.4204 / Val Loss: 0.4693 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[93/200] Train Loss: 0.4201 / Val Loss: 0.4692 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[94/200] Train Loss: 0.4199 / Val Loss: 0.4689 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[95/200] Train Loss: 0.4197 / Val Loss: 0.4688 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[96/200] Train Loss: 0.4195 / Val Loss: 0.4686 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[97/200] Train Loss: 0.4193 / Val Loss: 0.4684 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[98/200] Train Loss: 0.4191 / Val Loss: 0.4682 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[99/200] Train Loss: 0.4189 / Val Loss: 0.4680 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[100/200] Train Loss: 0.4187 / Val Loss: 0.4678 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[101/200] Train Loss: 0.4185 / Val Loss: 0.4677 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[102/200] Train Loss: 0.4183 / Val Loss: 0.4675 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[103/200] Train Loss: 0.4181 / Val Loss: 0.4674 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[104/200] Train Loss: 0.4179 / Val Loss: 0.4672 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[105/200] Train Loss: 0.4177 / Val Loss: 0.4671 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[106/200] Train Loss: 0.4175 / Val Loss: 0.4669 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[107/200] Train Loss: 0.4174 / Val Loss: 0.4668 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[108/200] Train Loss: 0.4172 / Val Loss: 0.4667 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[109/200] Train Loss: 0.4170 / Val Loss: 0.4666 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[110/200] Train Loss: 0.4169 / Val Loss: 0.4664 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[111/200] Train Loss: 0.4167 / Val Loss: 0.4663 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[112/200] Train Loss: 0.4165 / Val Loss: 0.4662 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[113/200] Train Loss: 0.4164 / Val Loss: 0.4661 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[114/200] Train Loss: 0.4162 / Val Loss: 0.4660 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[115/200] Train Loss: 0.4161 / Val Loss: 0.4659 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[116/200] Train Loss: 0.4159 / Val Loss: 0.4657 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[117/200] Train Loss: 0.4158 / Val Loss: 0.4657 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[118/200] Train Loss: 0.4156 / Val Loss: 0.4656 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[119/200] Train Loss: 0.4155 / Val Loss: 0.4655 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[120/200] Train Loss: 0.4153 / Val Loss: 0.4654 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[121/200] Train Loss: 0.4152 / Val Loss: 0.4653 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[122/200] Train Loss: 0.4151 / Val Loss: 0.4652 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[123/200] Train Loss: 0.4149 / Val Loss: 0.4651 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[124/200] Train Loss: 0.4148 / Val Loss: 0.4650 / Val Acc: 0.8180 / Change Acc: 0.2182\n",
            "[125/200] Train Loss: 0.4147 / Val Loss: 0.4650 / Val Acc: 0.8180 / Change Acc: 0.2182\n",
            "[126/200] Train Loss: 0.4145 / Val Loss: 0.4649 / Val Acc: 0.8180 / Change Acc: 0.2182\n",
            "[127/200] Train Loss: 0.4144 / Val Loss: 0.4648 / Val Acc: 0.8180 / Change Acc: 0.2182\n",
            "[128/200] Train Loss: 0.4143 / Val Loss: 0.4647 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[129/200] Train Loss: 0.4141 / Val Loss: 0.4647 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[130/200] Train Loss: 0.4140 / Val Loss: 0.4646 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[131/200] Train Loss: 0.4139 / Val Loss: 0.4646 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[132/200] Train Loss: 0.4138 / Val Loss: 0.4645 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[133/200] Train Loss: 0.4137 / Val Loss: 0.4644 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[134/200] Train Loss: 0.4135 / Val Loss: 0.4644 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[135/200] Train Loss: 0.4134 / Val Loss: 0.4643 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[136/200] Train Loss: 0.4133 / Val Loss: 0.4643 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[137/200] Train Loss: 0.4132 / Val Loss: 0.4642 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[138/200] Train Loss: 0.4131 / Val Loss: 0.4642 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[139/200] Train Loss: 0.4130 / Val Loss: 0.4641 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[140/200] Train Loss: 0.4129 / Val Loss: 0.4641 / Val Acc: 0.8146 / Change Acc: 0.2182\n",
            "[141/200] Train Loss: 0.4128 / Val Loss: 0.4640 / Val Acc: 0.8146 / Change Acc: 0.2182\n",
            "[142/200] Train Loss: 0.4126 / Val Loss: 0.4640 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[143/200] Train Loss: 0.4125 / Val Loss: 0.4640 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[144/200] Train Loss: 0.4124 / Val Loss: 0.4639 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[145/200] Train Loss: 0.4123 / Val Loss: 0.4639 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[146/200] Train Loss: 0.4122 / Val Loss: 0.4638 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[147/200] Train Loss: 0.4121 / Val Loss: 0.4638 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[148/200] Train Loss: 0.4120 / Val Loss: 0.4638 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[149/200] Train Loss: 0.4119 / Val Loss: 0.4637 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[150/200] Train Loss: 0.4118 / Val Loss: 0.4637 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[151/200] Train Loss: 0.4117 / Val Loss: 0.4637 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[152/200] Train Loss: 0.4116 / Val Loss: 0.4636 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[153/200] Train Loss: 0.4115 / Val Loss: 0.4636 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[154/200] Train Loss: 0.4114 / Val Loss: 0.4636 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[155/200] Train Loss: 0.4113 / Val Loss: 0.4636 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[156/200] Train Loss: 0.4112 / Val Loss: 0.4636 / Val Acc: 0.8129 / Change Acc: 0.2182\n",
            "[157/200] Train Loss: 0.4111 / Val Loss: 0.4635 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[158/200] Train Loss: 0.4110 / Val Loss: 0.4635 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[159/200] Train Loss: 0.4109 / Val Loss: 0.4635 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[160/200] Train Loss: 0.4108 / Val Loss: 0.4635 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[161/200] Train Loss: 0.4107 / Val Loss: 0.4635 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[162/200] Train Loss: 0.4106 / Val Loss: 0.4635 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[163/200] Train Loss: 0.4106 / Val Loss: 0.4634 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[164/200] Train Loss: 0.4105 / Val Loss: 0.4634 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[165/200] Train Loss: 0.4104 / Val Loss: 0.4634 / Val Acc: 0.8112 / Change Acc: 0.2182\n",
            "[166/200] Train Loss: 0.4103 / Val Loss: 0.4634 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[167/200] Train Loss: 0.4102 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[168/200] Train Loss: 0.4101 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[169/200] Train Loss: 0.4100 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[170/200] Train Loss: 0.4099 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[171/200] Train Loss: 0.4098 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[172/200] Train Loss: 0.4097 / Val Loss: 0.4634 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[173/200] Train Loss: 0.4096 / Val Loss: 0.4634 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[174/200] Train Loss: 0.4095 / Val Loss: 0.4634 / Val Acc: 0.8095 / Change Acc: 0.2182\n",
            "[175/200] Train Loss: 0.4095 / Val Loss: 0.4633 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[176/200] Train Loss: 0.4094 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[177/200] Train Loss: 0.4093 / Val Loss: 0.4633 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[178/200] Train Loss: 0.4092 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[179/200] Train Loss: 0.4091 / Val Loss: 0.4634 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[180/200] Train Loss: 0.4090 / Val Loss: 0.4634 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[181/200] Train Loss: 0.4089 / Val Loss: 0.4634 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[182/200] Train Loss: 0.4088 / Val Loss: 0.4634 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[183/200] Train Loss: 0.4087 / Val Loss: 0.4634 / Val Acc: 0.8061 / Change Acc: 0.2182\n",
            "[184/200] Train Loss: 0.4086 / Val Loss: 0.4634 / Val Acc: 0.8044 / Change Acc: 0.2182\n",
            "Early stopping at epoch 185\n",
            "Test Result: test_loss=0.4953 / test_acc=0.6990 / test_change_acc=0.3750\n",
            "Training with lr=0.0001, hidden_dim=128, strict_mode=False\n",
            "[1/200] Train Loss: 0.7031 / Val Loss: 0.7019 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[2/200] Train Loss: 0.6943 / Val Loss: 0.6911 / Val Acc: 0.8180 / Change Acc: 0.2364\n",
            "[3/200] Train Loss: 0.6845 / Val Loss: 0.6777 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[4/200] Train Loss: 0.6710 / Val Loss: 0.6586 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[5/200] Train Loss: 0.6509 / Val Loss: 0.6305 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[6/200] Train Loss: 0.6211 / Val Loss: 0.5922 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[7/200] Train Loss: 0.5831 / Val Loss: 0.5532 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[8/200] Train Loss: 0.5504 / Val Loss: 0.5311 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[9/200] Train Loss: 0.5335 / Val Loss: 0.5230 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[10/200] Train Loss: 0.5249 / Val Loss: 0.5205 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[11/200] Train Loss: 0.5187 / Val Loss: 0.5196 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[12/200] Train Loss: 0.5132 / Val Loss: 0.5190 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[13/200] Train Loss: 0.5075 / Val Loss: 0.5184 / Val Acc: 0.7058 / Change Acc: 0.3636\n",
            "[14/200] Train Loss: 0.5013 / Val Loss: 0.5175 / Val Acc: 0.7041 / Change Acc: 0.3455\n",
            "[15/200] Train Loss: 0.4944 / Val Loss: 0.5162 / Val Acc: 0.7041 / Change Acc: 0.3455\n",
            "[16/200] Train Loss: 0.4868 / Val Loss: 0.5142 / Val Acc: 0.7041 / Change Acc: 0.3455\n",
            "[17/200] Train Loss: 0.4786 / Val Loss: 0.5113 / Val Acc: 0.7041 / Change Acc: 0.3455\n",
            "[18/200] Train Loss: 0.4705 / Val Loss: 0.5074 / Val Acc: 0.7058 / Change Acc: 0.3273\n",
            "[19/200] Train Loss: 0.4631 / Val Loss: 0.5032 / Val Acc: 0.7058 / Change Acc: 0.3273\n",
            "[20/200] Train Loss: 0.4571 / Val Loss: 0.4993 / Val Acc: 0.7041 / Change Acc: 0.3091\n",
            "[21/200] Train Loss: 0.4523 / Val Loss: 0.4959 / Val Acc: 0.7041 / Change Acc: 0.2909\n",
            "[22/200] Train Loss: 0.4487 / Val Loss: 0.4932 / Val Acc: 0.7041 / Change Acc: 0.2727\n",
            "[23/200] Train Loss: 0.4459 / Val Loss: 0.4910 / Val Acc: 0.7143 / Change Acc: 0.2727\n",
            "[24/200] Train Loss: 0.4436 / Val Loss: 0.4891 / Val Acc: 0.7160 / Change Acc: 0.2727\n",
            "[25/200] Train Loss: 0.4417 / Val Loss: 0.4876 / Val Acc: 0.7194 / Change Acc: 0.2727\n",
            "[26/200] Train Loss: 0.4402 / Val Loss: 0.4863 / Val Acc: 0.7194 / Change Acc: 0.2727\n",
            "[27/200] Train Loss: 0.4388 / Val Loss: 0.4851 / Val Acc: 0.7194 / Change Acc: 0.2727\n",
            "[28/200] Train Loss: 0.4376 / Val Loss: 0.4841 / Val Acc: 0.7211 / Change Acc: 0.2727\n",
            "[29/200] Train Loss: 0.4365 / Val Loss: 0.4832 / Val Acc: 0.7211 / Change Acc: 0.2727\n",
            "[30/200] Train Loss: 0.4356 / Val Loss: 0.4824 / Val Acc: 0.7245 / Change Acc: 0.2727\n",
            "[31/200] Train Loss: 0.4346 / Val Loss: 0.4816 / Val Acc: 0.7245 / Change Acc: 0.2727\n",
            "[32/200] Train Loss: 0.4338 / Val Loss: 0.4809 / Val Acc: 0.7245 / Change Acc: 0.2727\n",
            "[33/200] Train Loss: 0.4330 / Val Loss: 0.4802 / Val Acc: 0.7262 / Change Acc: 0.2727\n",
            "[34/200] Train Loss: 0.4322 / Val Loss: 0.4796 / Val Acc: 0.7245 / Change Acc: 0.2545\n",
            "[35/200] Train Loss: 0.4315 / Val Loss: 0.4790 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[36/200] Train Loss: 0.4308 / Val Loss: 0.4784 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[37/200] Train Loss: 0.4302 / Val Loss: 0.4779 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[38/200] Train Loss: 0.4295 / Val Loss: 0.4773 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[39/200] Train Loss: 0.4289 / Val Loss: 0.4768 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[40/200] Train Loss: 0.4283 / Val Loss: 0.4763 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[41/200] Train Loss: 0.4277 / Val Loss: 0.4758 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[42/200] Train Loss: 0.4272 / Val Loss: 0.4753 / Val Acc: 0.7279 / Change Acc: 0.2364\n",
            "[43/200] Train Loss: 0.4266 / Val Loss: 0.4748 / Val Acc: 0.7296 / Change Acc: 0.2545\n",
            "[44/200] Train Loss: 0.4261 / Val Loss: 0.4743 / Val Acc: 0.7296 / Change Acc: 0.2545\n",
            "[45/200] Train Loss: 0.4256 / Val Loss: 0.4739 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[46/200] Train Loss: 0.4251 / Val Loss: 0.4734 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[47/200] Train Loss: 0.4246 / Val Loss: 0.4730 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[48/200] Train Loss: 0.4242 / Val Loss: 0.4725 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[49/200] Train Loss: 0.4237 / Val Loss: 0.4721 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[50/200] Train Loss: 0.4233 / Val Loss: 0.4717 / Val Acc: 0.7279 / Change Acc: 0.2545\n",
            "[51/200] Train Loss: 0.4228 / Val Loss: 0.4713 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[52/200] Train Loss: 0.4224 / Val Loss: 0.4709 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[53/200] Train Loss: 0.4220 / Val Loss: 0.4705 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[54/200] Train Loss: 0.4216 / Val Loss: 0.4701 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[55/200] Train Loss: 0.4212 / Val Loss: 0.4697 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[56/200] Train Loss: 0.4208 / Val Loss: 0.4693 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[57/200] Train Loss: 0.4204 / Val Loss: 0.4689 / Val Acc: 0.7313 / Change Acc: 0.2545\n",
            "[58/200] Train Loss: 0.4201 / Val Loss: 0.4686 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[59/200] Train Loss: 0.4197 / Val Loss: 0.4682 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[60/200] Train Loss: 0.4194 / Val Loss: 0.4679 / Val Acc: 0.7279 / Change Acc: 0.2182\n",
            "[61/200] Train Loss: 0.4190 / Val Loss: 0.4675 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[62/200] Train Loss: 0.4187 / Val Loss: 0.4672 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[63/200] Train Loss: 0.4183 / Val Loss: 0.4668 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[64/200] Train Loss: 0.4180 / Val Loss: 0.4665 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[65/200] Train Loss: 0.4177 / Val Loss: 0.4662 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[66/200] Train Loss: 0.4174 / Val Loss: 0.4659 / Val Acc: 0.7296 / Change Acc: 0.2182\n",
            "[67/200] Train Loss: 0.4171 / Val Loss: 0.4655 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[68/200] Train Loss: 0.4168 / Val Loss: 0.4652 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[69/200] Train Loss: 0.4165 / Val Loss: 0.4649 / Val Acc: 0.7279 / Change Acc: 0.2000\n",
            "[70/200] Train Loss: 0.4162 / Val Loss: 0.4646 / Val Acc: 0.7296 / Change Acc: 0.2000\n",
            "[71/200] Train Loss: 0.4159 / Val Loss: 0.4643 / Val Acc: 0.7296 / Change Acc: 0.2000\n",
            "[72/200] Train Loss: 0.4156 / Val Loss: 0.4641 / Val Acc: 0.7296 / Change Acc: 0.2000\n",
            "[73/200] Train Loss: 0.4154 / Val Loss: 0.4638 / Val Acc: 0.7296 / Change Acc: 0.2000\n",
            "[74/200] Train Loss: 0.4151 / Val Loss: 0.4635 / Val Acc: 0.7313 / Change Acc: 0.2000\n",
            "[75/200] Train Loss: 0.4148 / Val Loss: 0.4632 / Val Acc: 0.7313 / Change Acc: 0.2000\n",
            "[76/200] Train Loss: 0.4146 / Val Loss: 0.4630 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[77/200] Train Loss: 0.4143 / Val Loss: 0.4627 / Val Acc: 0.7330 / Change Acc: 0.2000\n",
            "[78/200] Train Loss: 0.4141 / Val Loss: 0.4624 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[79/200] Train Loss: 0.4138 / Val Loss: 0.4622 / Val Acc: 0.7296 / Change Acc: 0.1818\n",
            "[80/200] Train Loss: 0.4136 / Val Loss: 0.4619 / Val Acc: 0.7296 / Change Acc: 0.1818\n",
            "[81/200] Train Loss: 0.4133 / Val Loss: 0.4617 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[82/200] Train Loss: 0.4131 / Val Loss: 0.4615 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[83/200] Train Loss: 0.4128 / Val Loss: 0.4612 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[84/200] Train Loss: 0.4126 / Val Loss: 0.4610 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[85/200] Train Loss: 0.4124 / Val Loss: 0.4608 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[86/200] Train Loss: 0.4122 / Val Loss: 0.4606 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[87/200] Train Loss: 0.4119 / Val Loss: 0.4604 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[88/200] Train Loss: 0.4117 / Val Loss: 0.4602 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[89/200] Train Loss: 0.4115 / Val Loss: 0.4600 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[90/200] Train Loss: 0.4113 / Val Loss: 0.4598 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[91/200] Train Loss: 0.4110 / Val Loss: 0.4596 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[92/200] Train Loss: 0.4108 / Val Loss: 0.4594 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[93/200] Train Loss: 0.4106 / Val Loss: 0.4592 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[94/200] Train Loss: 0.4104 / Val Loss: 0.4590 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[95/200] Train Loss: 0.4102 / Val Loss: 0.4589 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[96/200] Train Loss: 0.4100 / Val Loss: 0.4587 / Val Acc: 0.7313 / Change Acc: 0.1818\n",
            "[97/200] Train Loss: 0.4098 / Val Loss: 0.4585 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[98/200] Train Loss: 0.4096 / Val Loss: 0.4584 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[99/200] Train Loss: 0.4094 / Val Loss: 0.4582 / Val Acc: 0.7330 / Change Acc: 0.1818\n",
            "[100/200] Train Loss: 0.4092 / Val Loss: 0.4581 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[101/200] Train Loss: 0.4090 / Val Loss: 0.4580 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[102/200] Train Loss: 0.4088 / Val Loss: 0.4578 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[103/200] Train Loss: 0.4086 / Val Loss: 0.4577 / Val Acc: 0.7347 / Change Acc: 0.1818\n",
            "[104/200] Train Loss: 0.4084 / Val Loss: 0.4576 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[105/200] Train Loss: 0.4082 / Val Loss: 0.4574 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[106/200] Train Loss: 0.4080 / Val Loss: 0.4573 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[107/200] Train Loss: 0.4078 / Val Loss: 0.4572 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[108/200] Train Loss: 0.4076 / Val Loss: 0.4571 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[109/200] Train Loss: 0.4074 / Val Loss: 0.4570 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[110/200] Train Loss: 0.4072 / Val Loss: 0.4569 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[111/200] Train Loss: 0.4070 / Val Loss: 0.4568 / Val Acc: 0.7364 / Change Acc: 0.1818\n",
            "[112/200] Train Loss: 0.4068 / Val Loss: 0.4567 / Val Acc: 0.7381 / Change Acc: 0.1818\n",
            "[113/200] Train Loss: 0.4066 / Val Loss: 0.4566 / Val Acc: 0.7381 / Change Acc: 0.1818\n",
            "[114/200] Train Loss: 0.4065 / Val Loss: 0.4566 / Val Acc: 0.7381 / Change Acc: 0.1818\n",
            "[115/200] Train Loss: 0.4063 / Val Loss: 0.4565 / Val Acc: 0.7381 / Change Acc: 0.1818\n",
            "[116/200] Train Loss: 0.4061 / Val Loss: 0.4564 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[117/200] Train Loss: 0.4059 / Val Loss: 0.4564 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[118/200] Train Loss: 0.4057 / Val Loss: 0.4563 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[119/200] Train Loss: 0.4055 / Val Loss: 0.4562 / Val Acc: 0.7398 / Change Acc: 0.1818\n",
            "[120/200] Train Loss: 0.4053 / Val Loss: 0.4562 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[121/200] Train Loss: 0.4052 / Val Loss: 0.4562 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[122/200] Train Loss: 0.4050 / Val Loss: 0.4561 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[123/200] Train Loss: 0.4048 / Val Loss: 0.4561 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[124/200] Train Loss: 0.4046 / Val Loss: 0.4560 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[125/200] Train Loss: 0.4044 / Val Loss: 0.4560 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[126/200] Train Loss: 0.4043 / Val Loss: 0.4560 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[127/200] Train Loss: 0.4041 / Val Loss: 0.4560 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[128/200] Train Loss: 0.4039 / Val Loss: 0.4560 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[129/200] Train Loss: 0.4037 / Val Loss: 0.4560 / Val Acc: 0.7415 / Change Acc: 0.1818\n",
            "[130/200] Train Loss: 0.4036 / Val Loss: 0.4559 / Val Acc: 0.7432 / Change Acc: 0.1818\n",
            "[131/200] Train Loss: 0.4034 / Val Loss: 0.4559 / Val Acc: 0.7432 / Change Acc: 0.1818\n",
            "[132/200] Train Loss: 0.4032 / Val Loss: 0.4559 / Val Acc: 0.7432 / Change Acc: 0.1818\n",
            "[133/200] Train Loss: 0.4030 / Val Loss: 0.4560 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[134/200] Train Loss: 0.4029 / Val Loss: 0.4560 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[135/200] Train Loss: 0.4027 / Val Loss: 0.4560 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[136/200] Train Loss: 0.4025 / Val Loss: 0.4560 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[137/200] Train Loss: 0.4024 / Val Loss: 0.4560 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[138/200] Train Loss: 0.4022 / Val Loss: 0.4560 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[139/200] Train Loss: 0.4020 / Val Loss: 0.4561 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "[140/200] Train Loss: 0.4018 / Val Loss: 0.4561 / Val Acc: 0.7449 / Change Acc: 0.1818\n",
            "Early stopping at epoch 141\n",
            "Test Result: test_loss=0.5076 / test_acc=0.7730 / test_change_acc=0.5312\n",
            "Training with lr=0.0001, hidden_dim=128, strict_mode=True\n",
            "[1/200] Train Loss: 0.6964 / Val Loss: 0.6935 / Val Acc: 0.6616 / Change Acc: 0.3636\n",
            "[2/200] Train Loss: 0.6876 / Val Loss: 0.6829 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[3/200] Train Loss: 0.6782 / Val Loss: 0.6704 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[4/200] Train Loss: 0.6657 / Val Loss: 0.6532 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[5/200] Train Loss: 0.6473 / Val Loss: 0.6280 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[6/200] Train Loss: 0.6194 / Val Loss: 0.5917 / Val Acc: 0.2942 / Change Acc: 0.6364\n",
            "[7/200] Train Loss: 0.5815 / Val Loss: 0.5520 / Val Acc: 0.6701 / Change Acc: 0.4545\n",
            "[8/200] Train Loss: 0.5478 / Val Loss: 0.5290 / Val Acc: 0.7993 / Change Acc: 0.2727\n",
            "[9/200] Train Loss: 0.5307 / Val Loss: 0.5204 / Val Acc: 0.8078 / Change Acc: 0.2364\n",
            "[10/200] Train Loss: 0.5221 / Val Loss: 0.5176 / Val Acc: 0.8078 / Change Acc: 0.2182\n",
            "[11/200] Train Loss: 0.5160 / Val Loss: 0.5164 / Val Acc: 0.8078 / Change Acc: 0.1818\n",
            "[12/200] Train Loss: 0.5105 / Val Loss: 0.5156 / Val Acc: 0.8129 / Change Acc: 0.2364\n",
            "[13/200] Train Loss: 0.5049 / Val Loss: 0.5148 / Val Acc: 0.8163 / Change Acc: 0.2182\n",
            "[14/200] Train Loss: 0.4991 / Val Loss: 0.5138 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[15/200] Train Loss: 0.4927 / Val Loss: 0.5125 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[16/200] Train Loss: 0.4856 / Val Loss: 0.5108 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "[17/200] Train Loss: 0.4778 / Val Loss: 0.5084 / Val Acc: 0.8146 / Change Acc: 0.1455\n",
            "[18/200] Train Loss: 0.4699 / Val Loss: 0.5051 / Val Acc: 0.8214 / Change Acc: 0.1818\n",
            "[19/200] Train Loss: 0.4624 / Val Loss: 0.5010 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[20/200] Train Loss: 0.4560 / Val Loss: 0.4969 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[21/200] Train Loss: 0.4510 / Val Loss: 0.4932 / Val Acc: 0.8231 / Change Acc: 0.2182\n",
            "[22/200] Train Loss: 0.4472 / Val Loss: 0.4901 / Val Acc: 0.8248 / Change Acc: 0.2545\n",
            "[23/200] Train Loss: 0.4443 / Val Loss: 0.4876 / Val Acc: 0.8231 / Change Acc: 0.2727\n",
            "[24/200] Train Loss: 0.4420 / Val Loss: 0.4855 / Val Acc: 0.8163 / Change Acc: 0.2545\n",
            "[25/200] Train Loss: 0.4401 / Val Loss: 0.4839 / Val Acc: 0.8180 / Change Acc: 0.2545\n",
            "[26/200] Train Loss: 0.4385 / Val Loss: 0.4825 / Val Acc: 0.8214 / Change Acc: 0.2545\n",
            "[27/200] Train Loss: 0.4372 / Val Loss: 0.4813 / Val Acc: 0.8180 / Change Acc: 0.2545\n",
            "[28/200] Train Loss: 0.4360 / Val Loss: 0.4803 / Val Acc: 0.8146 / Change Acc: 0.2545\n",
            "[29/200] Train Loss: 0.4349 / Val Loss: 0.4795 / Val Acc: 0.8197 / Change Acc: 0.2909\n",
            "[30/200] Train Loss: 0.4339 / Val Loss: 0.4787 / Val Acc: 0.8197 / Change Acc: 0.2727\n",
            "[31/200] Train Loss: 0.4330 / Val Loss: 0.4780 / Val Acc: 0.8214 / Change Acc: 0.2727\n",
            "[32/200] Train Loss: 0.4321 / Val Loss: 0.4774 / Val Acc: 0.8214 / Change Acc: 0.2727\n",
            "[33/200] Train Loss: 0.4313 / Val Loss: 0.4768 / Val Acc: 0.8214 / Change Acc: 0.2727\n",
            "[34/200] Train Loss: 0.4306 / Val Loss: 0.4763 / Val Acc: 0.8214 / Change Acc: 0.2545\n",
            "[35/200] Train Loss: 0.4299 / Val Loss: 0.4758 / Val Acc: 0.8214 / Change Acc: 0.2545\n",
            "[36/200] Train Loss: 0.4293 / Val Loss: 0.4753 / Val Acc: 0.8231 / Change Acc: 0.2545\n",
            "[37/200] Train Loss: 0.4286 / Val Loss: 0.4749 / Val Acc: 0.8248 / Change Acc: 0.2545\n",
            "[38/200] Train Loss: 0.4280 / Val Loss: 0.4744 / Val Acc: 0.8248 / Change Acc: 0.2545\n",
            "[39/200] Train Loss: 0.4275 / Val Loss: 0.4740 / Val Acc: 0.8231 / Change Acc: 0.2364\n",
            "[40/200] Train Loss: 0.4269 / Val Loss: 0.4736 / Val Acc: 0.8214 / Change Acc: 0.2182\n",
            "[41/200] Train Loss: 0.4264 / Val Loss: 0.4732 / Val Acc: 0.8231 / Change Acc: 0.2364\n",
            "[42/200] Train Loss: 0.4259 / Val Loss: 0.4728 / Val Acc: 0.8214 / Change Acc: 0.2182\n",
            "[43/200] Train Loss: 0.4254 / Val Loss: 0.4724 / Val Acc: 0.8197 / Change Acc: 0.2182\n",
            "[44/200] Train Loss: 0.4249 / Val Loss: 0.4721 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[45/200] Train Loss: 0.4245 / Val Loss: 0.4717 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[46/200] Train Loss: 0.4240 / Val Loss: 0.4713 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[47/200] Train Loss: 0.4236 / Val Loss: 0.4710 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[48/200] Train Loss: 0.4232 / Val Loss: 0.4706 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[49/200] Train Loss: 0.4228 / Val Loss: 0.4702 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[50/200] Train Loss: 0.4224 / Val Loss: 0.4699 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[51/200] Train Loss: 0.4220 / Val Loss: 0.4696 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[52/200] Train Loss: 0.4216 / Val Loss: 0.4692 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[53/200] Train Loss: 0.4212 / Val Loss: 0.4689 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[54/200] Train Loss: 0.4209 / Val Loss: 0.4685 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[55/200] Train Loss: 0.4205 / Val Loss: 0.4682 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[56/200] Train Loss: 0.4202 / Val Loss: 0.4679 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[57/200] Train Loss: 0.4198 / Val Loss: 0.4676 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[58/200] Train Loss: 0.4195 / Val Loss: 0.4673 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[59/200] Train Loss: 0.4192 / Val Loss: 0.4670 / Val Acc: 0.8180 / Change Acc: 0.1818\n",
            "[60/200] Train Loss: 0.4188 / Val Loss: 0.4667 / Val Acc: 0.8197 / Change Acc: 0.1818\n",
            "[61/200] Train Loss: 0.4185 / Val Loss: 0.4664 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[62/200] Train Loss: 0.4182 / Val Loss: 0.4661 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[63/200] Train Loss: 0.4179 / Val Loss: 0.4658 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[64/200] Train Loss: 0.4176 / Val Loss: 0.4655 / Val Acc: 0.8163 / Change Acc: 0.1818\n",
            "[65/200] Train Loss: 0.4173 / Val Loss: 0.4652 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[66/200] Train Loss: 0.4171 / Val Loss: 0.4649 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[67/200] Train Loss: 0.4168 / Val Loss: 0.4647 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[68/200] Train Loss: 0.4165 / Val Loss: 0.4644 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[69/200] Train Loss: 0.4163 / Val Loss: 0.4641 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[70/200] Train Loss: 0.4160 / Val Loss: 0.4639 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[71/200] Train Loss: 0.4157 / Val Loss: 0.4636 / Val Acc: 0.8163 / Change Acc: 0.2000\n",
            "[72/200] Train Loss: 0.4155 / Val Loss: 0.4634 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[73/200] Train Loss: 0.4152 / Val Loss: 0.4631 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[74/200] Train Loss: 0.4150 / Val Loss: 0.4629 / Val Acc: 0.8231 / Change Acc: 0.2182\n",
            "[75/200] Train Loss: 0.4148 / Val Loss: 0.4626 / Val Acc: 0.8214 / Change Acc: 0.2182\n",
            "[76/200] Train Loss: 0.4145 / Val Loss: 0.4624 / Val Acc: 0.8214 / Change Acc: 0.2182\n",
            "[77/200] Train Loss: 0.4143 / Val Loss: 0.4622 / Val Acc: 0.8197 / Change Acc: 0.2182\n",
            "[78/200] Train Loss: 0.4141 / Val Loss: 0.4620 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[79/200] Train Loss: 0.4138 / Val Loss: 0.4617 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[80/200] Train Loss: 0.4136 / Val Loss: 0.4615 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[81/200] Train Loss: 0.4134 / Val Loss: 0.4613 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[82/200] Train Loss: 0.4132 / Val Loss: 0.4611 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[83/200] Train Loss: 0.4130 / Val Loss: 0.4609 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[84/200] Train Loss: 0.4128 / Val Loss: 0.4607 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[85/200] Train Loss: 0.4126 / Val Loss: 0.4605 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[86/200] Train Loss: 0.4124 / Val Loss: 0.4603 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[87/200] Train Loss: 0.4122 / Val Loss: 0.4601 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[88/200] Train Loss: 0.4120 / Val Loss: 0.4599 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[89/200] Train Loss: 0.4118 / Val Loss: 0.4598 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[90/200] Train Loss: 0.4116 / Val Loss: 0.4596 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[91/200] Train Loss: 0.4114 / Val Loss: 0.4594 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[92/200] Train Loss: 0.4112 / Val Loss: 0.4592 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[93/200] Train Loss: 0.4110 / Val Loss: 0.4591 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[94/200] Train Loss: 0.4108 / Val Loss: 0.4589 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[95/200] Train Loss: 0.4106 / Val Loss: 0.4587 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[96/200] Train Loss: 0.4104 / Val Loss: 0.4586 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[97/200] Train Loss: 0.4103 / Val Loss: 0.4584 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[98/200] Train Loss: 0.4101 / Val Loss: 0.4583 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[99/200] Train Loss: 0.4099 / Val Loss: 0.4581 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[100/200] Train Loss: 0.4097 / Val Loss: 0.4580 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[101/200] Train Loss: 0.4095 / Val Loss: 0.4578 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[102/200] Train Loss: 0.4094 / Val Loss: 0.4577 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[103/200] Train Loss: 0.4092 / Val Loss: 0.4576 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[104/200] Train Loss: 0.4090 / Val Loss: 0.4574 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[105/200] Train Loss: 0.4088 / Val Loss: 0.4573 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[106/200] Train Loss: 0.4087 / Val Loss: 0.4572 / Val Acc: 0.8265 / Change Acc: 0.2182\n",
            "[107/200] Train Loss: 0.4085 / Val Loss: 0.4571 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[108/200] Train Loss: 0.4083 / Val Loss: 0.4570 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[109/200] Train Loss: 0.4081 / Val Loss: 0.4568 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[110/200] Train Loss: 0.4080 / Val Loss: 0.4567 / Val Acc: 0.8248 / Change Acc: 0.2182\n",
            "[111/200] Train Loss: 0.4078 / Val Loss: 0.4566 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[112/200] Train Loss: 0.4076 / Val Loss: 0.4565 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[113/200] Train Loss: 0.4075 / Val Loss: 0.4564 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[114/200] Train Loss: 0.4073 / Val Loss: 0.4563 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[115/200] Train Loss: 0.4071 / Val Loss: 0.4562 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[116/200] Train Loss: 0.4069 / Val Loss: 0.4562 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[117/200] Train Loss: 0.4068 / Val Loss: 0.4561 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[118/200] Train Loss: 0.4066 / Val Loss: 0.4560 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[119/200] Train Loss: 0.4064 / Val Loss: 0.4559 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[120/200] Train Loss: 0.4063 / Val Loss: 0.4558 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[121/200] Train Loss: 0.4061 / Val Loss: 0.4558 / Val Acc: 0.8282 / Change Acc: 0.2000\n",
            "[122/200] Train Loss: 0.4059 / Val Loss: 0.4557 / Val Acc: 0.8282 / Change Acc: 0.2000\n",
            "[123/200] Train Loss: 0.4058 / Val Loss: 0.4556 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[124/200] Train Loss: 0.4056 / Val Loss: 0.4556 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[125/200] Train Loss: 0.4055 / Val Loss: 0.4555 / Val Acc: 0.8265 / Change Acc: 0.2000\n",
            "[126/200] Train Loss: 0.4053 / Val Loss: 0.4555 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[127/200] Train Loss: 0.4051 / Val Loss: 0.4554 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[128/200] Train Loss: 0.4050 / Val Loss: 0.4554 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[129/200] Train Loss: 0.4048 / Val Loss: 0.4553 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[130/200] Train Loss: 0.4046 / Val Loss: 0.4553 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[131/200] Train Loss: 0.4045 / Val Loss: 0.4552 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[132/200] Train Loss: 0.4043 / Val Loss: 0.4552 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[133/200] Train Loss: 0.4041 / Val Loss: 0.4552 / Val Acc: 0.8248 / Change Acc: 0.2000\n",
            "[134/200] Train Loss: 0.4040 / Val Loss: 0.4552 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[135/200] Train Loss: 0.4038 / Val Loss: 0.4551 / Val Acc: 0.8231 / Change Acc: 0.2000\n",
            "[136/200] Train Loss: 0.4037 / Val Loss: 0.4551 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[137/200] Train Loss: 0.4035 / Val Loss: 0.4551 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[138/200] Train Loss: 0.4033 / Val Loss: 0.4551 / Val Acc: 0.8214 / Change Acc: 0.2000\n",
            "[139/200] Train Loss: 0.4032 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[140/200] Train Loss: 0.4030 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[141/200] Train Loss: 0.4028 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[142/200] Train Loss: 0.4027 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[143/200] Train Loss: 0.4025 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[144/200] Train Loss: 0.4024 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[145/200] Train Loss: 0.4022 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[146/200] Train Loss: 0.4020 / Val Loss: 0.4551 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[147/200] Train Loss: 0.4019 / Val Loss: 0.4551 / Val Acc: 0.8197 / Change Acc: 0.2000\n",
            "[148/200] Train Loss: 0.4017 / Val Loss: 0.4551 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[149/200] Train Loss: 0.4016 / Val Loss: 0.4551 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[150/200] Train Loss: 0.4014 / Val Loss: 0.4551 / Val Acc: 0.8180 / Change Acc: 0.2000\n",
            "[151/200] Train Loss: 0.4013 / Val Loss: 0.4552 / Val Acc: 0.8146 / Change Acc: 0.1818\n",
            "Early stopping at epoch 152\n",
            "Test Result: test_loss=0.5074 / test_acc=0.6429 / test_change_acc=0.4688\n"
          ]
        }
      ]
    }
  ]
}